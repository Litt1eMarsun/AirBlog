---
title: 金融领域大模型微调
urlname: firpfewiggyo1fie
date: '2025-09-20 01:38:58'
updated: '2025-10-04 17:05:42'
description: '假设微调背景需求/技术选型——微调MVP版1.1. 公司及业务背景 背景知识：我们部门主要涉及的业务产品是1. 反向保理:（大企业钱周转不过来，利用大企业信用做担保，银行相信大企业，替大企业还钱给供应商，同时收利息）依托核心企业主体授信,以供应商收账款作为资产,将资产债券转移给银行,为供应商提...'
---
## 假设微调背景需求/技术选型——微调MVP版
### 公司及业务背景
 背景知识：我们部门主要涉及的业务产品是

1. 反向保理:（**大企业钱周转不过来，利用大企业信用做担保，银行相信大企业，替大企业还钱给供应商，同时收利息**）

依托核心企业主体授信,以供应商收账款作为资产,将资产债券转移给银行,为供应商提供应收账款支付,并帮助核心企业延长账期。 

2. 提前回款:（**小企业急需用钱，还没到大企业的打钱时间要提前拿钱，银行提前给钱，但是把利息钱扣下来，后面大企业规定时间还钱就行**）

依托核心企业主体授信&自有资金,以供应商的应收账款作为依据,在不延长账期的前提下,在账期到期前,供应商申请提前支付,并付出利息成本。 

3. 订单融资:（**供应商要贷款扩大生产之类的，要借钱，大企业担保，数据来支持**）

依托核心企业与供应商历史订单交易数据,以及核心企业配合银行提供一些担保措施,为供应商提供信用融资产品。

 4. 采购融资:（**经销商没钱进货了，大企业担保确实把钱给了他，然后银行定向打款给大企业**）

依托核心企业与经销商历史订单交易数据,核心企业配合银行提供一些风控措施(受托支付、担保回购),为经销商提供信用融资产品。

5. 经销融资:（**经销没钱仓储啊物流啊之类的，要借钱，银行直接通过历史数据来决定借不借钱**）

依托核心企业(无需参与)与经销商历史交易数据,结合本公司提供的数据增信,为经销商提供信用融资产品。 

这些业务支持银行选择，银行可以根据需求选择业务，对核心企业，下游企业，供应商等进行放款。

现在主营业务是发票相关，所以一直维护数据库，主要包含了依托核心企业与供应商历史订单交易数据，主要以一些发票信息存储，核心企业和供应商之间的交易发票，包含了交易金额，发票id，交易时间等等  

现在我们构建一个客服机器人，向银行经理进行业务产品推荐。比如说有些核心企业最近资金链没有办法周转，但是通过他的现金流明显可以看出他是有能力偿还债务的，这些核心企业银行的客户经理就可以找上，主动提供 反向保理 放贷需求，这样我们公司就需要一个客服来和客户经理进行沟通。  

### 需求详细分析，并给出MVP，后续迭代方向
1.  领域理解与知识库能力  （MVP）
+ 深刻理解反向保理、提前回款、订单/采购/经销融资的业务逻辑、风控点、常见合同条款与会计/发票术语（应收账款、账期、逾期、受托支付、回购等）。
+ 能访问并使用公司数据库中的发票、订单、流水、合同元数据作为事实依据。
2.  多轮对话与状态管理（Session / Memory）  
+ 支持多轮跟踪：记住会话中的企业、发票ID、之前的建议与客户经理反馈。
+ 能做 slot-filling（缺什么数据就问什么），避免重复问已有信息。
3. **推荐逻辑（模式学习）**
+ 根据 QA 习惯 → 学到“资金紧张 → 推荐提前回款”，“账期长 → 推荐保理”。
+ 不需要实时数据，只要学套路。
+ **依赖数据**：QA 数据中产品推荐的对话样本。
4. 实时检索与事实闭环（RAG / DB calls）
+ 不凭想象生成结论：必须在回答前通过 API/SQL/向量检索等方法抓取相关发票/交易证据，且在答复中明确引用证据（例如发票ID、金额、时间）。
+ 支持函数式调用（deterministic microservices）获取关键事实（比如 get_outstanding_invoices(enterprise_id)、get_cashflow(enterprise_id, 90d)）。
5. **统一话术与风格**
+ 表达专业、礼貌，不会答非所问。
+ 语言风格接近人类客服。
+ **依赖数据**：QA 样本；上线时可以通过提示词强化。

以上是MVP需求，风控需求后面再增加

### 数据集配比
| QA 对话数据 | 60% | 保证模型的“客服对话风格”和核心业务流程不会丢失 |
| --- | --- | --- |


| 专业领域知识（文档转化） | 30–35% | 强化专业知识，让回答更专业、更可靠 |
| --- | --- | --- |


| 结构化输出 / 特殊任务数据 | 5–10% | 提前打好基础，为后续功能升级做准备 |
| --- | --- | --- |


### QA数据集
#### 原始QA数据集处理
原始对话数据存在如下问题：

1. 没有特定任务，需要的训练数据需要有特定任务
2. 对话很乱，数据并不match，并不是一人一轮

对于第一个问题，需要提取特定任务，但是对于实际上的prompt没有办法这么高效的去提取任务

搭建了如下prompt处理流程

<details class="lake-collapse"><summary id="u332ba770"><span class="ne-text">待扩充处理流程</span></summary><p id="u8ab0734c" class="ne-p"><strong><span class="ne-text">解决方案 = 复杂的标注框架</span></strong></p><ul class="ne-ul"><li id="u708ff33d" data-lake-index-type="0"><strong><span class="ne-text">CoT (Chain of Thought)</span></strong></li></ul><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u9c55ecd1" data-lake-index-type="0"><span class="ne-text">让模型一步步推理，比如先总结销售提到的核心内容，再归纳出可能的任务。</span></li><li id="ue464377a" data-lake-index-type="0"><span class="ne-text">避免“一步到位”时容易乱猜。</span></li></ul></ul><ul class="ne-ul"><li id="u6adb1dec" data-lake-index-type="0"><strong><span class="ne-text">Reflection (反思)</span></strong></li></ul><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u24f00a54" data-lake-index-type="0"><span class="ne-text">生成完任务后，让模型自己检查：</span></li></ul></ul><ul class="ne-list-wrap"><ul class="ne-list-wrap"><ul ne-level="2" class="ne-ul"><li id="u66528ded" data-lake-index-type="0"><span class="ne-text">“我推断的任务是否和对话内容一致？”</span></li><li id="u0674b109" data-lake-index-type="0"><span class="ne-text">“有没有遗漏/误解？”</span></li></ul></ul></ul><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u97ad79bd" data-lake-index-type="0"><span class="ne-text">有点像自我纠错。</span></li></ul></ul><ul class="ne-ul"><li id="ubec2f510" data-lake-index-type="0"><strong><span class="ne-text">Multi-LLM Consistency (多模型一致性)</span></strong></li></ul><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u92b77c03" data-lake-index-type="0"><span class="ne-text">不止调用一个模型，而是多个不同模型或同一个模型多次采样，看看它们的答案是否一致。</span></li><li id="u6e04aa92" data-lake-index-type="0"><span class="ne-text">如果多数模型都认同“任务=推销健康险”，就更有信心。</span></li></ul></ul><ul class="ne-ul"><li id="u6250a02d" data-lake-index-type="0"><strong><span class="ne-text">Debating (辩论式生成)</span></strong></li></ul><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u24292ce4" data-lake-index-type="0"><span class="ne-text">两个或多个模型先各自提出答案，再互相“批评/反驳”，最后融合成一个更合理的结论。</span></li><li id="u4c8469cb" data-lake-index-type="0"><span class="ne-text">解决了“模型单边想当然”的问题。</span></li></ul></ul></details>
对于第二个问题，直接让大模型根据已有数据（任务和对话）对每个任务生成对话。





1. **贷前识别**（现金流、资质、需求）  
    1. 询问上述主营业务中每个环节的具体情况（资金情况，交易情况）
        1. 业务数据询问
            1. 进行了多少比交易？之类的常规交易
            2. 风险控制，是否存在大额风险交易？
            3. 直接对数据进行分析
    2. 对场内具体情况的需求逻辑判断
        1. 根据资金情况，交易情况判断是否有借贷需求？
        2. 资金情况是否算健康？交易情况是否算健康？
    3. 场外情况的需求逻辑判断
        1. 现在季节有没有可能对需求有影响？
2. **贷中匹配**（产品推荐、额度利率沟通）  
    1. 产品匹配，业务匹配
3. **贷后管理**（风险监控、数据支持）  
    1. 和贷前识别一致

#### 数据集格式


#### 数据清洗
##### 去重
同时在本数据中有很多重复，比如说问好，再见这种占据大量样本的数据，并且模型本身已经有能力了。放入这些样本占用太多了

场景比较相似，

+ 虽然任务不同（比如卖保险 vs 卖信用卡），但因为销售场景类似，很多问法、答法非常接近。
+ 如果通话内容几乎雷同，模型可能学不到任务差异，只会套用模板式回答。

举例说明一下：

+ **任务1：推销健康险**

```plain
客户: 这个产品贵吗？
销售: 我们现在有优惠活动，性价比很高。
```

+ **任务2：推销信用卡**

```plain
客户: 这个卡年费贵吗？
销售: 我们现在有优惠活动，性价比很高。
```

虽然任务不同，但对话几乎一模一样，差别只在“产品” vs “卡”。  
如果数据里充斥着这种“模板化对话”，模型可能忽略任务信息，学成“遇到问价格就答：我们有优惠”。

这两个综合来看就是样本比较不平衡，多样性无法保证的问题

首先看第一个问题，即礼貌用于比较多的问题

解决方案:

**想法**：对话的不同轮次（turn position）重要性不同。开场和收尾（问候、拜拜）占比大但信息量低，应降低它们被选作训练输出的概率；中间的“销售主干”轮次权重高。

**实现方法举例**：

+ 定义对每条销售话语的轮次位置 `pos`（1 表示第一句销售话，N 表示最后一句销售话），以及该通话销售的总销售轮次数 `N_sales`。
+ 设定一个简单的权重函数，例如：

```plain
if pos <= start_cutoff or pos > N_sales - end_cutoff:
    w_turn = low_weight   # 比如 0.1 或 0.2
else:
    w_turn = 1.0
```

例如 `start_cutoff=1, end_cutoff=1, low_weight=0.1` 表示首句和尾句只保留 10% 的概率。

+ 训练样本抽样时按 `w_turn` 进行加权采样。

**举例**：  
一通对话有销售 6 句，权重可能 `[0.1, 1.0, 1.0, 1.0, 1.0, 0.1]`，抽样时第1句/第6句被选中的概率远低于中间句。

**注意/变体**：

+ 不要把开场/结束完全删除，保留少量以维持模型应对礼貌话语的能力（比如按比例保留 5-10%）。
+ 可以把“重要性”连续化（如对靠近中间的turn给更高分），也可以对靠近销售关键节点（如报价、异议处理）动态加权（需要检测关键字）。
+ 有些开场/结尾包含关键信息（是否允许回访、客户情绪），需要单独保留标注。

解决问题2：语义重复比较多的问题：

+ 对每个训练样本（一般是 `task + history + target_sales_utterance` 或只用 `task+history`）计算句向量（用 BERT / Sentence-BERT / SimCSE 等）。
+ 用层次聚类（agglomerative/hierarchical）或 KMeans 聚类；通过阈值/簇数控制聚类粒度。
+ 对每个簇按策略采样：大簇下采样（只保留一定比例或最多保留 M 条），小簇可以全部保留或适度过采样。

再看第二个问题，语义重复的问题：

对于一条样本：

```markdown
task: 推销健康险
history: 
  客户: 保险太贵了
  销售: 我们有优惠活动
target_sales_utterance:
  销售: 而且保障范围比医保广，性价比很高
```

先确定要embedding并且聚类的对象，对所有的target_sales_utt转换成向量并进行聚类，因为要去掉重复的回答，而不是重复的上下文

接下来选取模型进行embedding:

常用的预训练模型：

+ **BERT**：最早的句向量模型，但直接取 [CLS] 效果不好，一般要加 pooling。
+ **Sentence-BERT (SBERT)**：对 BERT 进行了优化，更适合拿来做句子语义相似度。
+ **SimCSE**：在 SBERT 基础上进一步改进，相似度效果更好。
    - 输入一句话 → 输出 768 维向量（base 模型）。
    - 相似语义句子 → 向量余弦相似度接近 1。

因为聚类的目的是吧语义相似度比较高的数据分为一类，之后进行下采样，从而实现对相似语义的下采样。而实现这个目的最重要看两个参数

+ 聚类方法的选取
+ 聚类粒度的划分
    - 聚类粒度过大，则下采样可能丢失很多信息
    - 聚类粒度过小，则采样策略可能会失效（2句话怎么剔除10%），并且不会删去相似的结果

对于聚类方法的选取，首先 以 **cosine distance** 为主要度量，因为 sentence-embedding 常用 cosine  

选取方法可以有如下几种：

<details class="lake-collapse"><summary id="u93c5b97c"><span class="ne-text">聚类方法选取及控制粒度的方法</span></summary><ul class="ne-ul"><li id="u8031bda1" data-lake-index-type="0"><strong><span class="ne-text">KMeans：用 K 控制粒度</span></strong></li><li id="u67f83912" data-lake-index-type="0"><span class="ne-text">小 K → 粗；大 K → 细。</span></li><li id="u8a1304d2" data-lake-index-type="0"><span class="ne-text">经验式起点：</span><code class="ne-code"><span class="ne-text">K ≈ sqrt(N)</span></code><span class="ne-text"> 或 </span><code class="ne-code"><span class="ne-text">K ≈ N / 1000</span></code><span class="ne-text">（取决于你想把多少样本放到每簇）。</span></li><li id="uf3eedc17" data-lake-index-type="0"><span class="ne-text">自动选 K：用 elbow（SSE）、silhouette、Gap statistic。先在子集上搜索一组 K（例如 50,100,200,500,1000）观察度量变化。</span></li><li id="u279d0ceb" data-lake-index-type="0"><strong><span class="ne-text">层次聚类：用距离阈值或切割高度控制粒度</span></strong></li><li id="u5aea729a" data-lake-index-type="0"><span class="ne-text">方案 A（按距离阈值）：把 dendrogram cut at </span><code class="ne-code"><span class="ne-text">t</span></code><span class="ne-text">，例如 </span><code class="ne-code"><span class="ne-text">t = 0.2</span></code><span class="ne-text"> 表示把 cosine 距离 &gt; 0.2 的合并停止（阈值需试验）。</span></li></ul><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u656252ec" data-lake-index-type="0"><span class="ne-text">常见经验（cosine distance = 1 - cosine_sim）：</span></li></ul></ul><ul class="ne-list-wrap"><ul class="ne-list-wrap"><ul ne-level="2" class="ne-ul"><li id="ub40b6a65" data-lake-index-type="0"><code class="ne-code"><span class="ne-text">t ≈ 0.05~0.12</span></code><span class="ne-text">：非常严格（只有几乎相同的句子才合并）</span></li><li id="u6abb2b4b" data-lake-index-type="0"><code class="ne-code"><span class="ne-text">t ≈ 0.12~0.25</span></code><span class="ne-text">：中等（同一模板/轻微改写合并）</span></li><li id="u3a542a50" data-lake-index-type="0"><code class="ne-code"><span class="ne-text">t ≈ 0.25~0.4</span></code><span class="ne-text">：宽松（主题级别合并）</span></li></ul></ul></ul><ul class="ne-ul"><li id="u61c5dd95" data-lake-index-type="0"><span class="ne-text">方案 B（按簇数 n_clusters）：指定目标簇数（等同于 KMeans 的 K）。</span></li><li id="u11a224cf" data-lake-index-type="0"><strong><span class="ne-text">HDBSCAN：通过 min_cluster_size 控制（更鲁棒）</span></strong></li><li id="u0a353133" data-lake-index-type="0"><code class="ne-code"><span class="ne-text">min_cluster_size = 50~200</span></code><span class="ne-text"> 作为起点（取决于你的总量与业务下限），越大簇越稀疏被合并越多。</span></li></ul></details>
暂定选择层次聚类，因为观察层次聚类图更清晰，层次聚类的聚类粒度控制的参数有两种，按cluster和距离阈值

对于按照距离阈值而言：

方案 A（按距离阈值）：把 dendrogram cut at `t`，例如 `t = 0.2` 表示把 cosine 距离 > 0.2 的合并停止（阈值需试验）。

+ 常见经验（cosine distance = 1 - cosine_sim）：
    - `t ≈ 0.05~0.12`：非常严格（只有几乎相同的句子才合并）
    - `t ≈ 0.12~0.25`：中等（同一模板/轻微改写合并）
    - `t ≈ 0.25~0.4`：宽松（主题级别合并）

对于方案B

**用 K 控制粒度**

+ 小 K → 粗；大 K → 细。
+ 经验式起点：`K ≈ sqrt(N)` 或 `K ≈ N / 1000`（取决于你想把多少样本放到每簇）。
+ 自动选 K：用 elbow（SSE）、silhouette、Gap statistic。先在子集上搜索一组 K（例如 50,100,200,500,1000）观察度量变化。

这里应该把选取出来的数据抽样拿出来看一看，每个聚类代表了什么，直到合适为止，之后按照一定原则进行下采样。

这里原则应该是保证数据集的分布？数据集分布的保证原则是什么？得喊大模型举例说明

之后下采样的策略同样如此，感觉按照比例下采样就够了（业务加权）

最后可以获得足量的，去除重复的数据

##### 前期清洗工作：
1. 对于导入进来的QA，csv简单过滤，转化为特定message格式之后进行清除
    - 文本之外的消息
    - 转发的消息，空字符，特殊字符清理
    - block的消息

```python
def _load_single_csv(self, csv_file: Path) -> List[Message]:
        """加载单个CSV文件"""
        messages = []
        
        try:
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # 检查消息类型是否在允许范围内
                    if row['type_name'] not in self.include_type:
                        continue
                        
                    # 检查是否为转发消息
                    if int(row.get('is_forward', 0)) == 1:
                        continue
                    
                    # 清理和验证消息内容
                    cleaned_msg = self._clean_message(row['msg'])
                    if not cleaned_msg or self._is_blocked_message(cleaned_msg):
                        continue
                    
                    message = Message(
                        id=row['id'],
                        msg_svr_id=row['MsgSvrID'],
                        type_name=row['type_name'],
                        is_sender=int(row['is_sender']),
                        talker=row['talker'],
                        msg=cleaned_msg,
                        src=row['src'],
                        create_time=self._parse_time(row['CreateTime']),
                        room_name=row['room_name'],
                        is_forward=int(row['is_forward'])
                    )
                    messages.append(message)
                    
        except Exception as e:
            self.logger.error(f"读取CSV文件 {csv_file} 时发生错误: {e}")
            
        return messages
```

2. 消息合并
    1. 多条短消息合并为一条消息
3. QA对生成：
    1. 在一定的时间窗口内形成问答对，实际上按天分就行了，因为每次对话基本上都是一天一个话题









    2. 向前回溯不超过token数量的上下文即可，并检验是否超长

```json
  def _build_context(self, messages: List[Message], current_index: int) -> List[ChatMLMessage]:
        """构建上下文消息"""
        context_messages = []
        context_length = 0
        
        # 向前查找上下文，但要控制长度
        for i in range(max(0, current_index - 10), current_index):
            msg = messages[i]
            
            # 确定角色：is_sender=1表示AI发送（assistant），is_sender=0表示用户发送（user）
            role = "assistant" if msg.is_sender == 1 else "user"
            
            # 检查添加后是否超长
            if context_length + len(msg.msg) > self.messages_max_length // 2:
                break
                
            context_messages.append(ChatMLMessage(role, msg.msg))
            context_length += len(msg.msg)
        
        return context_messages  
```

4. 

##### PII
1. 正则表达式处理。比如说之前涉及到具体发票单号，可能涉及的客户手机号等等，这样处理看能不能覆盖全部
    1. 正则处理到的数据都保留到内网处理
2. 设计block_words，比如政治相关的常用敏感词库
3. presidio library进行PII详见weclone，库

##### 无关信息筛选（闲聊等降低比重）——少量有关系吗


##### 去重
+ 精确重复：同一对话被多次保存。
+ 语义重复：不同表述但含义几乎相同（“账期90天→90天账期”）。

##### 大模型打分
#### 数据增强
##### 提供证据背景信息(证据链接对）
#####  结构化建议/动作标签（JSON 输出样例）  
```json
{
  "recommended_product":"提前回款",
  "recommended_amount":600000,
  "recommended_rate_range":"5.5%-6.5%",
  "confidence":0.78,
  "risk_score":0.42,
  "risk_reasons":["供应商集中度高","发票异常:inv_20250901_12345"],
  "evidence":["inv_20250901_12345"],
  "escalate_to_human":false
}

```





#### 处理之后的干净QA数据集示意：
##### 核心企业资质与现金流情况 
**场景：客户经理想判断某核心企业的资金状况**

+ **M**：最近我听说A集团资金链有点紧，你们那边数据能看出他们的现金流情况吗？
+ **C**：我们看了最近6个月的交易流水，A集团的现金流波动确实加大，但核心业务的回款周期正常，没有大额逾期。从偿债能力来看，还是比较健康的。
+ **M**：他们有没有频繁申请提前回款？
+ **C**：有的，近两个月提前回款的申请量比去年同期多了30%，可能是短期周转压力。

##### 供应商/经销商的信用与资金需求  
**场景：客户经理要识别哪些供应商有潜在贷款需求**

+ **M**：哪些供应商最近资金压力比较大，可能需要融资？
+ **C**：根据数据，B公司账期90天，但他们平均在40天左右就会申请提前支付，说明现金流紧张，适合推荐保理或提前回款类融资。
+ **M**：经销商呢？有没有比较急需资金的？
+ **C**：D经销商最近下了大额订单，但没有相应资金支持，他们过去两次使用采购融资的频率增加，可能需要主动联系。

##### 宏观环境影响贷款需求  
**场景： 行业与市场因素  **

+ **M**：最近建材行业是不是资金压力都比较大？
+ **C**：对的，原材料涨价叠加旺季开工，很多核心企业和供应商都增加了提前回款申请，建议您重点关注这条产业链的企业。
+ **M**：那农产品行业呢？
+ **C**：农产品有季节性因素，上游采购旺季通常会出现短期资金缺口，可以针对经销商推荐采购融资产品。

##### 贷款产品与匹配策略  
**场景：帮客户经理判断合适的融资产品**

+ **M**：C公司有一笔大额应收账款快到期了，他们适合哪种产品？
+ **C**：如果只是短期周转，可以推荐提前回款；如果他们想延长账期，可以考虑反向保理。
+ **M**：那经销商呢？我怎么知道该推经销融资还是采购融资？
+ **C**：如果核心企业愿意提供担保或受托支付，可以走采购融资；如果核心企业不参与，就可以用我们提供数据增信的经销融资。

#####  风控与合规沟通  
**场景：风险预警与合规要求**

+ **M**：有没有发现核心企业的异常情况？
+ **C**：有一个核心企业最近连续两次开具了金额异常的大额发票，我们已经标记为风险提示，建议您审慎放贷。
+ **M**：需要做哪些合规检查？
+ **C**：我们会帮您核查核心企业及上下游是否涉及诉讼、被执行或反洗钱名单，您可以在授信前再做一次交叉验证。

#####  数据服务与支持  
**场景：客户经理需要具体数据来支撑放贷决策**

+ **M**：能给我出一份关于E企业的现金流健康度报告吗？
+ **C**：没问题，我们会包含交易规模、回款周期、逾期率等指标，下周一发给您。
+ **M**：我还想知道他们供应商的集中度情况。
+ **C**：我们统计过，前五大供应商占比超过70%，有一定依赖风险，这部分会写在报告里。

##### 贷后管理与跟踪  
**场景：放贷后持续跟踪风险**

+ **M**：上个月放贷的F公司最近情况怎么样？
+ **C**：我们监控到他们提前回款申请减少，说明资金压力有所缓解，整体风险下降。
+ **M**：那G企业呢？
+ **C**：G企业有一笔应收账款逾期超过15天，这是第一次出现这种情况，建议您跟进确认原因。



1. 已有客户经理和客服人员的对话数据集，希望从中学到
    - 说话风格
    - 部分知识内容
    2. 为什么不用rlhf？

每个流程都做，效果会更好一点，后面也会做。

    3. 为什么不用全参量微调？
        1. 了解一下在当前场景下，使用什么微调更合适，多大模型合适尽量扯一扯理由
        2. 数据量原因

我现在有十万条qa指令qa数据，是客服和银行客户经理的沟通的，大概内容是银行经理像客服询问发票的政策，不同公司的发票金额等等。

我希望微调一个大模型来代替客服，让大模型从对话中而获得QA中的金融领域知识，发票领域知识，客服和银行经理的说话风格

### 领域知识数据集
产品说明，包含了反向保理，提前回款等产品知识，这些必须要理解。其实大模型对这些金融基础知识有一定了解，知识让他更熟悉公司产品，要不然没办法真实说明。

详细看花园code的指令式微调即可

### 技术架构(微调版）


### 评估指标
## 第二次迭代需求
1. 结构化输出与可执行动作
+ 除自然语言外，能输出标准化 JSON/action（推荐产品、额度、利率区间、推荐理由、证据引用、风险标签、是否需人工审批），便于前端/自动化流程消费与审计。
2. **风险信号识别**

风险控制模型参考：https://zhuanlan.zhihu.com/p/16249193321

+ 学会从对话中识别“逾期/账期过长/单一客户依赖度高”等风险信号。
+ **需要数据**：构造风险对话样例（可人工合成），标注风险类别。
3. **话术灵活性**
+ 不同场景下会有不同回复方式（比如敏感问题答“请联系风险团队”）。
+ **需要数据**：QA 数据 + 少量人工补充“拒答/转人工”的对话。
4. 可解释性（Explainability）
+ 对推荐给出“top-3 驱动因子”（例如：应收账款覆盖率、逾期率、供应商集中度）并用数据支撑。

### 数据处理
1. 增加了语音转换功能
2. 增强上下文的长度，有些对话情况会用到前几天的对话作为上下文，（上一次说的之类的）——需要把前几天的对话总结作为上下文





## 待思考内容
1. 技术细节？
2. 怎么去编排哪个问题是第几次迭代产生的这种？
3. 创造的数据是不是应该带think cot，怎么带？
4. 聚类的时候是对所有的回答进行聚类吗，当前对话的问答进行据类？
5. 具体选择什么模型？对比一下，应该选取哪个？如何量化对比结果？
6. 顺序如何保证，哪个效果更好？

## <font style="color:#000000;">DISC-FinLLM: A Chinese Financial Large Language Model</font><font style="color:#000000;">  
</font><font style="color:#000000;">based on Multiple Experts Fine-tuning</font>
### 数据处理


## FinGPT
项目地址：



先打算跑通benchmark，看看评分

[https://github.com/AI4Finance-Foundation/FinGPT/blob/master/fingpt/FinGPT_Benchmark/demo.ipynb](https://github.com/AI4Finance-Foundation/FinGPT/blob/master/fingpt/FinGPT_Benchmark/demo.ipynb)

代码解释下：

```plain
def load_model(base_model, peft_model, from_remote=False):
    
    model_name = parse_model_name(base_model, from_remote)

    model = AutoModelForCausalLM.from_pretrained(
        model_name, trust_remote_code=True, 
        device_map="auto",
    )
    model.model_parallel = True

    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    
    tokenizer.padding_side = "left"
    if base_model == 'qwen':
        tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids('<|endoftext|>')
        tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids('<|extra_0|>')
    if not tokenizer.pad_token or tokenizer.pad_token_id == tokenizer.eos_token_id:
        tokenizer.add_special_tokens({'pad_token': '[PAD]'})
        model.resize_token_embeddings(len(tokenizer))
    
    model = PeftModel.from_pretrained(model, peft_model)
    model = model.eval()
    return model, tokenizer
```

首先这里chattemplet没改，感觉像是通用的。只是把最重要的eos和padding改了下，就直接把prompt输入到toknizer了。GPT说是因为输入的prompt写死的，但是具体可以展开看下。

其次padding方法可以深究一下，详细看看八股的padding部分

```plain
def test_demo(model, tokenizer):

    for task_name, input, instruction in zip(demo_tasks, demo_inputs, demo_instructions):
        prompt = 'Instruction: {instruction}\nInput: {input}\nAnswer: '.format(
            input=input, 
            instruction=instruction
        )
        inputs = tokenizer(
            prompt, return_tensors='pt',
            padding=True, max_length=512,
            return_token_type_ids=False
        )
        inputs = {key: value.to(model.device) for key, value in inputs.items()}
        res = model.generate(
            **inputs, max_length=512, do_sample=False,
            eos_token_id=tokenizer.eos_token_id
        )
        output = tokenizer.decode(res[0], skip_special_tokens=True)
        print(f"\n==== {task_name} ====\n")
        print(output)
```

这里直接把task作为instraction输入，input作为input输入。但是好像没有过templet，直接使用了。

