---
title: 微调
urlname: rehgmieu9m33y084
date: '2025-09-17 23:31:34'
updated: '2025-10-11 16:54:06'
cover: 'https://cdn.nlark.com/yuque/0/2025/png/43288584/1756486547256-3e53e739-03d0-41b9-86bf-294ff8678b54.png'
description: 1. 数据准备 1.1. 一般框架流程按照多种特定模板处理好数据（多种数据格式）按照框架内部格式调整成一般通用数据把通用数据再次针对每个实际使用的模型格式化为特定templet，就可以直接输入大模型了如果不是框架，只是1.2. 数据集构建1.2.1. 格式参照alpaca格式，给出instra...
---
## 数据准备		
### 一般框架流程
1. 按照多种特定模板处理好数据（多种数据格式）
2. 按照框架内部格式调整成一般通用数据
3. 把通用数据再次针对每个实际使用的模型格式化为特定templet，就可以直接输入大模型了

> 如果不是框架，只是
>

### 数据集构建
#### 格式
参照alpaca格式，给出instraction和input output,就构建成了一段对话数据集

Instruction:和input进行拼接，作为模型输入。

同时instruction中一般套了函数调用工具，，最后渲染之后以tools和tools 包裹，详见下面

数据多了模型就学会了调用

```json
<|im_start|>system
你是一名助人为乐的助手。当用户查询天气的时候，请调用get_weather函数进行天气信息查询。
# Tools
 You may call one or more functions to assist with the user query.
 You are provided with function signatures within <tools></tools> XML tags:
 <tools>
 {"name": "get_weather", "description": "查询指定城市的天气信息", "parameters": 
{"type": "object", "properties": {"location": {"type": "string", "description": 
"要查询天气的城市名称"}}, "required": ["location"]}}
 </tools>
For each function call, return a json object with function name and arguments 
within <tool_call></tool_call> XML tags:
 <tool_call>
 {"name": <function-name>, "arguments": <args-json-object>}
 </tool_call>
 <|im_end|>
 <|im_start|>user
你好，请帮我查询下北京天气。<|im_end|>
 <|im_start|>assistant
 <tool_call>
 {"name": "get_weather", "arguments": {"location": "北京"}}
 </tool_call><|im_end|>
```

如果带有思考链，就在assistant的输出中间加上think这个tag让模型来学习

```json
<|im_start|>system
你是一名助人为乐的助手。<|im_end|>
 <|im_start|>user
你好，好久不见。<|im_end|>
 <|im_start|>assistant
 <think>
好的，用户发来“你好，好久不见！”，我需要回应。首先，用户可能希望得到亲切的回应，所以应该用友好的
语气。
</think>
是的呀，好久不见，最近有什么有趣的事情要和我分享么？<|im_end|
```

（当然，加上思考链还有别的方法）

如果需要增加think和funciton call功能，则在think过程当中表达了需要调用工具的过程，并在assitant的回复里加上tools calltag

最后的输出如下：

```json
<|im_start|>system
你是一名助人为乐的助手。当用户查询天气的时候，请调用get_weather函数进行天气信息查询。
# Tools
 You may call one or more functions to assist with the user query.
 You are provided with function signatures within <tools></tools> XML tags:
 <tools>
 {"name": "get_weather", "description": "查询指定城市的天气信息", "parameters": 
{"type": "object", "properties": {"location": {"type": "string", "description": 
"要查询天气的城市名称"}}, "required": ["location"]}}
 </tools>
 For each function call, return a json object with function name and arguments 
within <tool_call></tool_call> XML tags:
 <tool_call>
 {"name": <function-name>, "arguments": <args-json-object>}
 </tool_call>
 <|im_end|>
 <|im_start|>user
你好，请帮我查询下北京天气。<|im_end|>
 <|im_start|>assistant
 <think>
好的，用户问北京今天的天气，我应该尝试调用工具 get_weather，并将参数设置为北京。
</think>
 <tool_call>
{"name": "get_weather", "arguments": {"location": "北京"}}
 </tool_call><|im_end|>
```

实际情况更复杂，可能是tools-call之类的tag

#### 数据集构造
##### 保留原始大模型能力
1. 混合推理能力

在构造微调上数据集的时候仍然混合think和没有think tag的数据集

    1. 在普通对话的时候不保留think，非普通对话时保留think 
2. 

## 微调技术
感觉学到面对一个清洗好的数据集，能够精准的训练到loss下降到一定程度，验证机测试集下降到一定程度就ok了

### 应用场景
1. 推理能力提升（对话逻辑需要学习，比如说推荐逻辑之类的）
2. 知识灌注（偏重于让模型理解大概，细节查询还得需要挂RAG，类似于让给模型概念性的知识，但是具体考试还得要查答案）
3. Agent能力（MCP的能力）

### 基础知识
#### PEFT
QLoRA[https://zhuanlan.zhihu.com/p/666234324](https://zhuanlan.zhihu.com/p/666234324)这里有篇详细解释的

2. QLora使用的量化技术：先不看了，感觉从基础的量化技术到QLora量化技术有着太长的距离 
3. 部分sft

<details class="lake-collapse"><summary id="u26edb085"><span class="ne-text">逐层微调</span></summary></details>
<details class="lake-collapse"><summary id="u7e53bb85"><span class="ne-text">冻结微调</span></summary><p id="u09091bc0" class="ne-p"><br></p></details>
4. prompt tuning

<details class="lake-collapse"><summary id="u01cb3fb3"><span class="ne-text">例子理解</span></summary><h3 id="UZGVN"><span class="ne-text">场景</span></h3><p id="u77a76319" class="ne-p"><span class="ne-text">假设我们有一个已经训练好的大模型（比如 GPT 风格），它很强，但我们要让它在 </span><strong><span class="ne-text">影评情感分类</span></strong><span class="ne-text"> 上表现更好。</span></p><h3 id="fMEGz"><span class="ne-text">原始做法</span></h3><p id="u5df6ff2f" class="ne-p"><span class="ne-text">如果不用 prompt tuning，你可能写：</span></p><pre data-language="plain" id="QC9p6" class="ne-codeblock language-plain"><code>&quot;Review: The movie was too long and boring. Sentiment:&quot;</code></pre><p id="u84cf5b3d" class="ne-p"><span class="ne-text">模型可能输出：</span></p><pre data-language="plain" id="NAooO" class="ne-codeblock language-plain"><code>Negative</code></pre><p id="u820a9e7f" class="ne-p"><span class="ne-text">但模型不一定稳定，因为它不是专门训练在情感分类任务上的。</span></p><hr id="pt4gy" class="ne-hr"><h3 id="GbAbD"><span class="ne-text">Prompt tuning 的做法</span></h3><ol class="ne-ol"><li id="ua9c096ae" data-lake-index-type="0"><strong><span class="ne-text">加上虚拟的提示 embedding</span></strong><span class="ne-text"><br /></span><span class="ne-text">在输入前面，我们不放文字，而是放一串 </span><strong><span class="ne-text">可学习的 embedding</span></strong><span class="ne-text">，比如 </span><code class="ne-code"><span class="ne-text">[p1, p2, ..., p20]</span></code><span class="ne-text">，长度 20。<br /></span><span class="ne-text">这段 embedding 最开始是随机的。</span></li></ol><p id="ub717a313" class="ne-p"><span class="ne-text">输入就变成：</span></p><pre data-language="plain" id="TUhwI" class="ne-codeblock language-plain"><code>[p1, p2, ..., p20, &quot;Review: The movie was too long and boring. Sentiment:&quot;]</code></pre><ol start="2" class="ne-ol"><li id="u4eba9f25" data-lake-index-type="0"><strong><span class="ne-text">训练</span></strong></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u9f7bd68d" data-lake-index-type="0"><span class="ne-text">给模型很多影评和对应的情感标签。</span></li><li id="u4dbb908e" data-lake-index-type="0"><span class="ne-text">用 loss 来更新 </span><strong><span class="ne-text">只有 </span></strong><code class="ne-code"><strong><span class="ne-text">[p1, ..., p20]</span></strong></code><strong><span class="ne-text"> 这些 embedding</span></strong><span class="ne-text">，模型本体完全冻结。</span></li></ul></ul><ol start="3" class="ne-ol"><li id="u31e3d4b3" data-lake-index-type="0"><strong><span class="ne-text">结果</span></strong></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u1ffb6621" data-lake-index-type="0"><span class="ne-text">训练后的 </span><code class="ne-code"><span class="ne-text">[p1, ..., p20]</span></code><span class="ne-text"> 学会了“暗示”模型：看到它们就进入“情感分类模式”。</span></li><li id="ubc5c0eb6" data-lake-index-type="0"><span class="ne-text">之后无论输入什么影评，只要带上这段虚拟 prompt，模型就会稳定输出情感标签。</span></li></ul></ul><h3 id="bdb44700"><span class="ne-text">类比理解</span></h3><p id="uac7194c4" class="ne-p"><span class="ne-text">你可以把 prompt tuning 想成：</span></p><ul class="ne-ul"><li id="ub37a55d8" data-lake-index-type="0"><span class="ne-text">在大模型的脑子里，埋了一个“密码”。</span></li><li id="u8d220f10" data-lake-index-type="0"><span class="ne-text">当输入带着这个“密码”（训练好的 embedding），模型就知道“啊，现在我该做情感分类了”。</span></li><li id="u3b9993a8" data-lake-index-type="0"><span class="ne-text">密码本身不是人能读懂的文字，而是模型自己学出来的一种信号。</span></li></ul></details>


#### SFT
#### 硬件
![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1758521165093-edc01af1-b2a0-436c-b6e4-d6db0de59fe2.png)



#### 硬件需求
Qwen系列：

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1758444779890-52d51932-57d5-4439-b411-8ee8cfe90408.png)

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1758444806345-3573792a-3ccc-4259-b685-d61e08d4e712.png)



### 微调工具
1. unsloth
2. Llamafactory
3. ms swift
4. colossal_AI

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1758435070760-9d3dba49-6412-4240-971a-bbd719b5c3c4.png)



## 模型观察


一般只要训练模型支持回调函数，就可以支持wandb，比如下面的weclone的训练启动文件，支持回调函数callbacks,具体看实现可以细细研究下

```python
def run_exp(args: Optional[dict[str, Any]] = None, callbacks: Optional[list["TrainerCallback"]] = None) -> None:
    args = read_args(args)
    if "-h" in args or "--help" in args:
        get_train_args(args)

    ray_args = get_ray_args(args)
    callbacks = callbacks or []
    if ray_args.use_ray:
        callbacks.append(RayTrainReportCallback())
        trainer = get_ray_trainer(
            training_function=_training_function,
            train_loop_config={"args": args, "callbacks": callbacks},
            ray_args=ray_args,
        )
        trainer.fit()
    else:
        _training_function(config={"args": args, "callbacks": callbacks})
```

之后在程序中初始化wandb,并

```python
from transformers.integrations import WandbCallback 
```



1. 结构化输出与可执行动作
+ 除自然语言外，能输出标准化 JSON/action（推荐产品、额度、利率区间、推荐理由、证据引用、风险标签、是否需人工审批），便于前端/自动化流程消费与审计。
2. **风险信号识别**

风险控制模型参考：https://zhuanlan.zhihu.com/p/16249193321

+ 学会从对话中识别“逾期/账期过长/单一客户依赖度高”等风险信号。
+ **需要数据**：构造风险对话样例（可人工合成），标注风险类别。
3. **话术灵活性**
+ 不同场景下会有不同回复方式（比如敏感问题答“请联系风险团队”）。
+ **需要数据**：QA 数据 + 少量人工补充“拒答/转人工”的对话。
4. 可解释性（Explainability）
+ 对推荐给出“top-3 驱动因子”（例如：应收账款覆盖率、逾期率、供应商集中度）并用数据支撑。

## 评价框架：
EvalScope

1. 多评测数据集，多评测方法，高度自动化，很好的可视化效果



## 
