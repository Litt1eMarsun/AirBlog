---
title: æ‰‹æ­åŸºæ¨¡_pretrainéƒ¨åˆ†ï¼š
urlname: viwnaxmwh5pzpnhe
date: '2025-08-06 10:17:58'
updated: '2025-11-11 11:22:10'
cover: 'https://cdn.nlark.com/yuque/0/2025/png/43288584/1754446737066-04b7bd38-3009-4a10-83d2-7e6faf7be854.png'
description: '1. tokenizerä¸­æ–‡æ¨¡å‹å¯¹ä¸­æ–‡çš„åˆ†è¯ä¼šæœ‰å•ç‹¬ä¼˜åŒ–ï¼Œä¸è‹±æ–‡æ¨¡å‹ä¸åŒã€‚æ‰€ä»¥ä¸èƒ½ç¡®å®šä¸€å¥è¯å…·ä½“å¯¹åº”ç€å¤šå°‘token 1.1. Word2vec(tokenizeræ­å»º)å‚è€ƒå†…å®¹https://zhuanlan.zhihu.com/p/55983009å®ç°äº†é€šè¿‡ç¥ç»ç½‘ç»œé«˜ç»´çš„å¥å­å‘ä½ç»´çš„vec...'
---


## tokenizer
ä¸­æ–‡æ¨¡å‹å¯¹ä¸­æ–‡çš„åˆ†è¯ä¼šæœ‰å•ç‹¬ä¼˜åŒ–ï¼Œä¸è‹±æ–‡æ¨¡å‹ä¸åŒã€‚æ‰€ä»¥ä¸èƒ½ç¡®å®šä¸€å¥è¯å…·ä½“å¯¹åº”ç€å¤šå°‘token 

### Word2vec(tokenizeræ­å»º)
å‚è€ƒå†…å®¹[https://zhuanlan.zhihu.com/p/55983009](https://zhuanlan.zhihu.com/p/55983009)

å®ç°äº†é€šè¿‡ç¥ç»ç½‘ç»œé«˜ç»´çš„å¥å­å‘ä½ç»´çš„vecè½¬åŒ–çš„è¿‡ç¨‹ã€‚vecè¦æœ‰è‡³å°‘ä»¥ä¸‹å‡ ä¸ªèƒ½åŠ›ï¼š

1. **<font style="color:rgb(25, 27, 31);">æºå¸¦ä¸Šä¸‹æ–‡ä¿¡æ¯</font>**
2. **<font style="color:rgb(25, 27, 31);">è¯çš„è¡¨ç¤ºæ˜¯ç¨ å¯†çš„</font>**

æ¨¡å‹ç¤ºæ„å›¾å¦‚ä¸‹

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1752737432814-795ebaa8-1d6b-4ebc-af9a-81b085526adc.png)

è¾“å…¥æ˜¯è¯æ±‡åº“ä¸­**<font style="color:rgb(25, 27, 31);">Vä¸ªå•è¯</font>**å•è¯æ•°é‡ï¼ŒHidden Layer**<font style="color:rgb(25, 27, 31);">ä¸ºå•è¯å‘é‡çš„ç»´åº¦ï¼Œ</font>**æ˜¯è‡ªå·±è®¾çš„è¶…å‚ä¹Ÿå°±æ˜¯Nï¼Œè¾“å‡ºå±‚å¤§å°å’Œè¾“å…¥å±‚æ•°é‡ä¸€è‡´ã€‚

ä¸¾ä¾‹ï¼Œå‡è®¾<font style="color:rgb(25, 27, 31);">è¯­æ–™åº“è¯æ±‡æœ‰å…«ä¸ªå•è¯['a','cat','chasing','climbed','dog','saw','the','tree']ï¼Œéšè—å±‚å¤§å°ä¸º3ï¼Œåˆ™WIä¸º8*3ï¼ŒWOä¸º3*8ã€‚</font>

<font style="color:rgb(25, 27, 31);">å…·ä½“çš„è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼š</font>

<font style="color:rgb(25, 27, 31);">è®­ç»ƒæ•°æ®æ˜¯å¤šä¸ªå¥å­ï¼ˆå½“ç„¶å¥å­ä¹Ÿå¯ä»¥æ’åˆ—ç»„åˆå½¢æˆæ›´å¤šå¥å­ï¼‰ï¼Œå¥å­ä¸­è‚¯å®šæ¯ä¸ªè¯è¯­éƒ½æºå¸¦äº†ä¸Šä¸‹æ–‡çš„ä¿¡æ¯ï¼Œä½†æ˜¯æ¨¡å‹çš„è®¾è®¡ä¹‹åˆï¼Œè¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯æ•´ä¸ªè¯æ±‡è¡¨çš„å¤§å°ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥æŠŠä¸€ä¸ªå¥å­æ ‡å¿—ä¸ºä¸€ä¸ªç‹¬çƒ­ç¼–ç ï¼Œå»è®©æ¨¡å‹å­¦ä¹ è¯è¯­ä¹‹é—´çš„å…³ç³»ï¼Œä¹Ÿå°±æ˜¯æ»¡è¶³äº†ä¹‹å‰æåˆ°çš„ç¬¬ä¸€ä¸ªè¦æ±‚ï¼š</font>**<font style="color:rgb(25, 27, 31);">æºå¸¦ä¸Šä¸‹æ–‡ä¿¡æ¯</font>**

<font style="color:rgb(25, 27, 31);">ä¸¾ä¸ªä¾‹å­ï¼šè¾“å…¥çš„å¥å­å¦‚æœæ˜¯â€œDog chasing catâ€ï¼Œæˆ‘ä»¬å¸Œæœ›ç½‘ç»œå­¦ä¹ å•è¯â€œcatâ€å’Œâ€œclimbedâ€ä¹‹é—´çš„å…³ç³»ã€‚</font>

<font style="color:rgb(25, 27, 31);">åˆ™æŒ‰ç†è¯´å½“â€œcatâ€è¾“å…¥åˆ°ç½‘ç»œæ—¶ï¼Œç½‘ç»œåº”è¯¥æ˜¾ç¤ºâ€œclimbedâ€çš„</font>**<font style="color:rgb(25, 27, 31);">é«˜æ¦‚ç‡</font>**<font style="color:rgb(25, 27, 31);">ã€‚åœ¨å•è¯åµŒå…¥æœ¯è¯­ä¸­ï¼Œå•è¯â€œcatâ€è¢«ç§°ä¸º</font>**<font style="color:rgb(25, 27, 31);">context word</font>**<font style="color:rgb(25, 27, 31);">ï¼Œå•è¯â€œclimbedâ€è¢«ç§°ä¸º</font>**<font style="color:rgb(25, 27, 31);">target word</font>**<font style="color:rgb(25, 27, 31);">ã€‚</font>

<font style="color:rgb(25, 27, 31);"></font>

### å…¶ä»–
å®é™…å·¥ç¨‹ä¸Šçš„ç‰¹æ®Šå­—ç¬¦å­˜åœ¨tokneizer_config.jsonå½“ä¸­

## æ—‹è½¬ä½ç½®ç¼–ç 
### è§’åº¦è®¾å®š
å…ˆå®šä¹‰å¦‚ä¸‹å‡½æ•°ï¼šä¹Ÿå°±æ˜¯ç»™ä¸åŒembeddingçš„ä¸åŒç»´åº¦çš„ç‰¹å®šæ—‹è½¬è§’åº¦

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754446737066-04b7bd38-3009-4a10-83d2-7e6faf7be854.png)

```plain
# æ³¨æ„ï¼šæ­¤å¤„çš„dimåº”ä¸º dim//n_headï¼Œå› ä¸ºæˆ‘ä»¬æ˜¯å¯¹æ¯ä¸ªheadè¿›è¡Œæ—‹è½¬åµŒå…¥
def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):
    # torch.arange(0, dim, 2)[: (dim // 2)].float()ç”Ÿæˆäº†ä¸€ä¸ªä»0å¼€å§‹ï¼Œæ­¥é•¿ä¸º2çš„åºåˆ—ï¼Œé•¿åº¦ä¸ºdimçš„ä¸€åŠ
    # ç„¶åæ¯ä¸ªå…ƒç´ é™¤ä»¥dimï¼Œå†å–thetaçš„å€’æ•°ï¼Œå¾—åˆ°é¢‘ç‡
    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))
    # ç”Ÿæˆä¸€ä¸ªä»0åˆ°endçš„åºåˆ—ï¼Œé•¿åº¦ä¸ºend
    t = torch.arange(end, device=freqs.device)
    # è®¡ç®—å¤–ç§¯ï¼Œå¾—åˆ°ä¸€ä¸ªäºŒç»´çŸ©é˜µï¼Œæ¯ä¸€è¡Œæ˜¯tçš„å…ƒç´ ä¹˜ä»¥freqsçš„å…ƒç´ 
    freqs = torch.outer(t, freqs).float()
    # è®¡ç®—é¢‘ç‡çš„ä½™å¼¦å€¼ï¼Œå¾—åˆ°å®éƒ¨
    freqs_cos = torch.cos(freqs)
    # è®¡ç®—é¢‘ç‡çš„æ­£å¼¦å€¼ï¼Œå¾—åˆ°è™šéƒ¨
    freqs_sin = torch.sin(freqs)
    return freqs_cos, freqs_sin

```

### å¹¿æ’­è§’åº¦  

ä¹‹åå¸¸è§„æ“ä½œï¼Œå¯¹freqè¿›è¡Œå¹¿æ’­æ–¹ä¾¿ä¸xåšä¹˜ç§¯

```python
def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):
    # è·å–xçš„ç»´åº¦æ•°
    ndim = x.ndim
    
    # æ–­è¨€ï¼Œç¡®ä¿1åœ¨xçš„ç»´åº¦èŒƒå›´å†…
    assert 0 <= 1 < ndim
    
    # æ–­è¨€ï¼Œç¡®ä¿freqs_cisçš„å½¢çŠ¶ä¸xçš„ç¬¬äºŒç»´å’Œæœ€åä¸€ç»´ç›¸åŒ
    assert freqs_cis.shape == (x.shape[1], x.shape[-1])
    
    # æ„é€ ä¸€ä¸ªæ–°çš„å½¢çŠ¶ï¼Œé™¤äº†ç¬¬äºŒç»´å’Œæœ€åä¸€ç»´ï¼Œå…¶ä»–ç»´åº¦éƒ½ä¸º1ï¼Œè¿™æ ·åšæ˜¯ä¸ºäº†èƒ½å¤Ÿå°†freqs_cisä¸xè¿›è¡Œå¹¿æ’­æ“ä½œ
    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]
    
    # å°†freqs_cisè°ƒæ•´ä¸ºæ–°çš„å½¢çŠ¶ï¼Œå¹¶è¿”å›
    return freqs_cis.view(shape)
```

  
 å¯¹äºå€’æ•°ç¬¬äºŒè¡Œï¼Œæ“ä½œè¿‡ç¨‹å¦‚ä¸‹ï¼š

```python
x.shape = (2, 128, 8, 64)  # batch=2, seq_len=128, n_head=8, head_dim=64
freqs_cis.shape = (128, 64)
```

+ reshape å‡ºæ¥çš„ shape ä¼šæ˜¯ `[1, 128, 1, 64]`ï¼Œå¯ä»¥å¹¿æ’­åˆ° `(2, 128, 8, 64)`
+ è¿™æ ·å¯ä»¥ç›´æ¥åšï¼š

x_rotated = x * reshape_for_broadcast(freqs_cis, x)

### æ—‹è½¬è¿‡ç¨‹å¦‚ä¸‹ï¼š
```python
def apply_rotary_emb(
    xq: torch.Tensor,
    xk: torch.Tensor,
    freqs_cos: torch.Tensor,
    freqs_sin: torch.Tensor
) -> Tuple[torch.Tensor, torch.Tensor]:

    # å°†æŸ¥è¯¢å’Œé”®å¼ é‡è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œå¹¶é‡å¡‘å½¢çŠ¶ä»¥åˆ†ç¦»å®éƒ¨å’Œè™šéƒ¨
    xq_r, xq_i = xq.float().reshape(xq.shape[:-1] + (-1, 2)).unbind(-1)
    xk_r, xk_i = xk.float().reshape(xk.shape[:-1] + (-1, 2)).unbind(-1)

    # é‡æ–°å¡‘å½¢é¢‘ç‡å¼ é‡ä»¥è¿›è¡Œå¹¿æ’­
    freqs_cos = reshape_for_broadcast(freqs_cos, xq_r)
    freqs_sin = reshape_for_broadcast(freqs_sin, xq_r)

    # åº”ç”¨æ—‹è½¬ï¼Œåˆ†åˆ«è®¡ç®—æ—‹è½¬åçš„å®éƒ¨å’Œè™šéƒ¨
    xq_out_r = xq_r * freqs_cos - xq_i * freqs_sin
    xq_out_i = xq_r * freqs_sin + xq_i * freqs_cos
    xk_out_r = xk_r * freqs_cos - xk_i * freqs_sin
    xk_out_i = xk_r * freqs_sin + xk_i * freqs_cos

    # å°†æœ€åä¸¤ä¸ªç»´åº¦åˆå¹¶ï¼Œå¹¶è¿˜åŸä¸ºåŸå§‹å¼ é‡çš„å½¢çŠ¶
    xq_out = torch.stack([xq_out_r, xq_out_i], dim=-1).flatten(3)
    xk_out = torch.stack([xk_out_r, xk_out_i], dim=-1).flatten(3)

    return xq_out.type_as(xq), xk_out.type_as(xk)
```

åŸç†å¦‚ä¸‹ï¼š  
å®é™…æ“ä½œæ˜¯æŠŠæ¯ä¸¤ä¸ªæ•°çœ‹æˆä¸€ä¸ªäºŒç»´å‘é‡åæ ‡å¹¶è¿›è¡Œæ—‹è½¬ã€‚æ‹†åˆ†æˆçš„32,2ä¸­çš„2åˆ†åˆ«è¿›è¡Œ

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754451824295-d45e01d4-1493-42f0-a4c0-4d247a23a349.png)

ä¹‹åå†æ‹¼æ¥åˆ°ä¸€èµ·å½¢æˆ[x',y;]è¿™æ ·å°±å¯¹æ‰€æœ‰embeddingè¿›è¡Œæ—‹è½¬äº†ã€‚åªæ˜¯æœ‰ä¸€ä¸ªå¤æ•°è¡¨è¾¾æ–¹å¼ç½¢äº†ï¼Œçº¯èŠ±æ´»

æŠŠä¹‹å‰å ªç§°çš„äºŒç»´å‘é‡åæ ‡ç°åœ¨çœ‹æˆå¤æ•°ï¼Œåˆ™æ—‹è½¬å¯ä»¥å¦‚ä¸‹è¡¨è¾¾ï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754451967516-ef3e5060-36bd-4b70-b64e-849f3cf7b81b.png)

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754451989250-f196b0a4-b5c7-4cd4-9355-1e8e8559559e.png)

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754452034637-11921ff6-204c-496f-b1a3-eae3456ede5a.png)

è¿™æ ·è¢«è§†ä¸ºå¤æ•°çš„ä¸¤ä¸ªåæ ‡å°±è¢«å˜å¹»æˆäº†å¦‚ä¸‹å½¢å¼ï¼Œä¹‹åå†æ‹¼æ¥ã€‚

ä»£ç é€è¡Œè§£é‡Š

1. xq_r, xq_i = xq.float().reshape(xq.shape[:-1] + (-1, 2)).unbind(-1)

æŠŠqueryçš„æœ€åä¸€ä¸ªç»´åº¦æ‹†åˆ†æˆä¸¤ä¸ªï¼Œå¹¶åˆ†åˆ«èµ‹ç»™sq_r,xq_i

å³(2, 128, 8, 64) â†’ (2, 128, 8, 32, 2),å¹¶åˆ†åˆ«èµ‹ç»™sq_r,xq_i

è¿™ä¸ªreshapeçš„åŸç†å¦‚ä¸‹ï¼š

`**reshape()**`** ä¸æ”¹å˜æ•°æ®çš„é¡ºåºï¼Œåªæ˜¯é‡æ–°è§£é‡Šå®ƒçš„å½¢çŠ¶ï¼ˆæŒ‰è¡Œä¸»åº row-major é¡ºåºï¼‰**ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼š

    - åŸå§‹çš„ `(2, 128, 8, 64)` ä¸­çš„æ‰€æœ‰æ•°æ®ï¼Œåœ¨å†…å­˜ä¸­æ˜¯ä¸€ä¸ªä¸€ç»´æ•°ç»„ï¼Œå…±æœ‰ `2Ã—128Ã—8Ã—64 = 131072` ä¸ªå…ƒç´ ã€‚
    - `reshape` åï¼Œ**ä¸ä¼šæ‰“ä¹±è¿™äº›å…ƒç´ çš„é¡ºåº**ï¼Œåªæ˜¯æŒ‰æ–°çš„ç»´åº¦è§£é‡Šå®ƒã€‚

æ¯”å¦‚è¯´

x = torch.arange(128, dtype=torch.float32)  # è¿™æ˜¯ä¸€ä¸ª 1D å‘é‡

x â†’ (64, 2)ï¼Œå…¶ä¸­ x[i, 0] æ˜¯å®éƒ¨ï¼Œx[i, 1] æ˜¯è™šéƒ¨

tensor([[ 0.,  1.],   # å¤æ•°1ï¼šå®éƒ¨0ï¼Œè™šéƒ¨1

        [ 2.,  3.],   # å¤æ•°2ï¼šå®éƒ¨2ï¼Œè™šéƒ¨3

        [ 4.,  5.],   # ...

        [ 6.,  7.],

        [ 8.,  9.]])

å…ˆåœ¨è¡Œä¸Šæ’ï¼Œå†æ’å³ã€‚

2. freqs_cos = reshape_for_broadcast(freqs_cos, xq_r)

å¹¿æ’­freq_coså’Œsinï¼Œæ–¹ä¾¿å’Œåé¢çš„ä¹˜ç§¯

3. xq_out_r = xq_r * freqs_cos - xq_i * freqs_sin     xq_out_i = xq_r * freqs_sin + xq_i * freqs_cos

å®éƒ¨ï¼Œè™šéƒ¨æ—‹è½¬

ç†è§£äº†æ—‹è½¬çŸ©é˜µæ€ä¹ˆæ¥çš„ï¼Œç°åœ¨çœ‹çœ‹ä¸ºä»€ä¹ˆèƒ½å‡¸æ˜¾å‡ºç›¸å¯¹ä½ç½®

<font style="color:rgb(25, 27, 31);">è®¾æ—‹è½¬çŸ©é˜µå¦‚ä¸‹å›¾æ‰€ç¤º</font>

```plain
R(pos) = [cos(posÂ·Î¸)  -sin(posÂ·Î¸)]
         [sin(posÂ·Î¸)   cos(posÂ·Î¸)]
```

ç°åœ¨å¯¹nä½ç½®çš„qçŸ©é˜µå’Œmä½ç½®çš„kçŸ©é˜µåº”ç”¨æ—‹è½¬çŸ©é˜µï¼Œç»“æœå¦‚ä¸‹å›¾æ‰€ç¤º

```plain
q_n = R(n) Â· Q = [cos(nÂ·Î¸)  -sin(nÂ·Î¸)] Â· Q
                 [sin(nÂ·Î¸)   cos(nÂ·Î¸)]
k_m = R(m) Â· K = [cos(mÂ·Î¸)  -sin(mÂ·Î¸)] Â· K
                 [sin(mÂ·Î¸)   cos(mÂ·Î¸)]
```

æœ€ç»ˆè¦å¯¹qå’Œkç®—æ³¨æ„åŠ›ä¹˜ç§¯ï¼Œä¹˜ç§¯è®¡ç®—çš„è¿‡ç¨‹å¦‚ä¸‹ï¼š

```plain
Attention(n,m) = q_n Â· k_m = (R(n)Â·Q) Â· (R(m)Â·K)
```

å®é™…æ˜¯Qçš„è½¬ç½®QTä¹˜K

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759495527857-3e4789b5-d127-4682-885c-ec19e21e40d5.png)

å› ä¸º![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759495546445-ece28c80-bbdc-48b2-aed9-9efb1c0a5570.png)



æ‰€ä»¥é‡æ–°æŠŠçŸ©é˜µç”¨æ¬§æ‹‰å…¬å¼è½¬æ¢ä¹˜Î¸å½¢å¼ä¹‹åå†ä¹˜ç§¯å°±æ˜¯å¦‚ä¸‹ç»“æœï¼ŒQtå’ŒKä¹‹é—´çš„ä¹˜ç§¯æ˜¯ä¸¤ä¸ªè§’åº¦ä¹‹å·®ï¼Œèƒ½å¤Ÿå®Œæˆä½ç½®ç¼–ç çš„ä½¿å‘½

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759495684372-7ce10aec-80d7-4081-9462-b653a1a0ddfa.png)





### NTK-awareåŠYARNç­‰åç»­çš„contextæ‰©å±•å·¥ä½œ
[https://zhuanlan.zhihu.com/p/20328774059](https://zhuanlan.zhihu.com/p/20328774059)

## RLHF
### PPO
####  æ•°æ®è·å–ï¼š ç¬¬ä¸€æ­¥ï¼šäººç±»è¯„å®¡ä¸¤ä¸ªå›ç­”ï¼Œå½¢æˆâ€œåå¥½å¯¹â€  
æ¯”å¦‚ä½ è¾“å…¥ä¸€ä¸ªæç¤ºï¼ˆpromptï¼‰ï¼š

"å¦‚ä½•å¤„ç†èŒåœºä¸­çš„äººé™…å…³ç³»ï¼Ÿ"

è¯­è¨€æ¨¡å‹ç”Ÿæˆäº†ä¸¤ä¸ªå›ç­”ï¼š

+ å›ç­” Aï¼šè¦å­¦ä¼šæ²Ÿé€šï¼Œå°Šé‡ä»–äººæ„è§ã€‚
+ å›ç­” Bï¼šç›´æ¥æ— è§†é‚£äº›ä¸å–œæ¬¢ä½ çš„äººï¼Œä¸ç”¨å¤ªåœ¨æ„ã€‚

äººç±»è¯„å®¡è€…è§‰å¾— A æ›´å¾—ä½“ï¼Œäºæ˜¯é€‰äº† Aã€‚

äºæ˜¯å½¢æˆä¸€æ¡è®­ç»ƒæ•°æ®ï¼š

```plain
(Prompt, Answer A, Answer B, preference: A)
```

ğŸ“Œ **è¿™å«åå¥½å¯¹ï¼ˆpreference pairï¼‰**ã€‚

ğŸ” ç°å®ä¸­ä¼šè®©è¯­è¨€æ¨¡å‹ç”Ÿæˆå¤šä¸ªå€™é€‰å›ç­”ï¼Œç„¶åè®©äººç±»å¯¹å…¶ä¸­ä¸¤ä¸ªæˆ–å¤šä¸ªæ‰“åˆ†æˆ–æ’åºã€‚

####  è®­ç»ƒä¸€ä¸ªâ€œå¥–åŠ±æ¨¡å‹â€ï¼ˆReward Modelï¼‰  
##### ğŸ“˜ ä»€ä¹ˆæ˜¯å¥–åŠ±æ¨¡å‹ï¼Ÿ
ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ªâ€œæ‰“åˆ†è€å¸ˆâ€ï¼Œä¸“é—¨æ ¹æ®å›ç­”è´¨é‡ç»™å‡ºåˆ†æ•°ã€‚

å®ƒçš„ç›®æ ‡æ˜¯ï¼šè¾“å…¥ä¸€ä¸ª prompt å’Œä¸€ä¸ªå›ç­”ï¼Œè¾“å‡ºä¸€ä¸ªåˆ†æ•°ï¼Œä»£è¡¨â€œè¿™ä¸ªå›ç­”æœ‰å¤šå¥½â€ã€‚

##### ğŸ§  æ€ä¹ˆè®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Ÿ
è¿™æ—¶å°±ç”¨ä¸Šé¢æ”¶é›†çš„äººç±»åå¥½å¯¹ï¼

æ¯”å¦‚ï¼šä½ å‘Šè¯‰æ¨¡å‹ï¼Œ"å›ç­” A æ¯” å›ç­” B æ›´å¥½"ï¼Œé‚£ä¹ˆå®ƒè¦å­¦ä¼šç»™ A çš„åˆ†æ•°æ¯” B é«˜ã€‚

è®­ç»ƒæ–¹å¼ä¸€èˆ¬æ˜¯ï¼š

+ è¾“å…¥ (Prompt, Answer A)ï¼Œæ¨¡å‹é¢„æµ‹åˆ†æ•° s_A
+ è¾“å…¥ (Prompt, Answer B)ï¼Œæ¨¡å‹é¢„æµ‹åˆ†æ•° s_B
+ ç”¨ä¸€ä¸ª loss å‡½æ•°æƒ©ç½š `s_A < s_B` çš„æƒ…å†µ

é€šå¸¸ä½¿ç”¨ä¸€ä¸ªå« **pairwise loss** çš„å‡½æ•°ï¼ˆæ¯”å¦‚ logistic lossï¼‰ï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754651230689-4a0c1250-a44c-4642-9670-ae850a826a92.png)

ğŸ‘‰ **ä¹Ÿå°±æ˜¯è®©æ¨¡å‹çš„åˆ†æ•°æœç€â€œäººç±»æ›´å–œæ¬¢çš„é‚£ä¸ªâ€é æ‹¢ã€‚**

#### ğŸ§ª ç¬¬ä¸‰æ­¥ï¼šç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–è¯­è¨€æ¨¡å‹ï¼ˆPPOç­‰ï¼‰
å¥½ï¼Œç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªâ€œæ‰“åˆ†è€å¸ˆâ€ï¼ˆå¥–åŠ±æ¨¡å‹ï¼‰ï¼Œä¸‹ä¸€æ­¥å°±æ˜¯ï¼š

ç”¨è¿™ä¸ªè€å¸ˆæ¥â€œæŒ‡å¯¼è¯­è¨€æ¨¡å‹â€ï¼šè®©å®ƒè¾“å‡ºåˆ†æ•°æ›´é«˜çš„å›ç­”ã€‚

è¿™ä¸€æ­¥ä½¿ç”¨çš„æ˜¯å¼ºåŒ–å­¦ä¹ ï¼ˆæ¯”å¦‚ PPOï¼šProximal Policy Optimizationï¼‰ã€‚

##### ğŸ¤– ä¸ºä»€ä¹ˆéœ€è¦å¼ºåŒ–å­¦ä¹ ï¼Ÿ
å› ä¸ºè¯­è¨€æ¨¡å‹æœ¬èº«è¾“å‡ºçš„æ˜¯â€œè¯æ¦‚ç‡â€ï¼Œä½†å¥–åŠ±æ¨¡å‹ä¸æ˜¯æ¦‚ç‡ï¼Œå®ƒæ˜¯ä¸€ä¸ªâ€œå¤–éƒ¨æ‰“åˆ†â€ç³»ç»Ÿã€‚

æˆ‘ä»¬ä¸èƒ½ç›´æ¥ç”¨â€œæ¢¯åº¦åå‘ä¼ æ’­â€æ¥ä¼˜åŒ–è¯­è¨€æ¨¡å‹ï¼Œè®©å®ƒçš„å›ç­”æ›´é«˜åˆ†ã€‚å› ä¸ºï¼š

+ **æ¨¡å‹è¾“å‡ºæ˜¯â€œç¦»æ•£çš„è¯â€**

å…·ä½“æ¥è¯´ï¼Œè¯­è¨€æ¨¡å‹è¾“å‡ºçš„æ˜¯ä¸€ä¸ªä¸ªè¯ï¼Œæ¯”å¦‚ï¼š

```plain
"ä½ å¥½ï¼Œä»Šå¤©çš„å¤©æ°”..."
```

åœ¨æ¨¡å‹å†…éƒ¨ï¼Œå®ƒå…¶å®ä¸æ˜¯ç›´æ¥è¾“å‡ºè¿™ä¸ªå¥å­ï¼Œè€Œæ˜¯ï¼š

åœ¨æ¯ä¸€ä¸ªä½ç½®ï¼Œé¢„æµ‹ä¸€ä¸ªè¯çš„ **æ¦‚ç‡åˆ†å¸ƒ**ï¼Œç„¶åä»ä¸­**é‡‡æ ·ï¼ˆæŠ½ç­¾ï¼‰**å‡ºä¸€ä¸ªè¯ã€‚

æ¯”å¦‚ï¼š

+ æ¨¡å‹é¢„æµ‹å½“å‰ä½ç½®çš„è¯æ˜¯ï¼š
    - â€œä½ å¥½â€ çš„æ¦‚ç‡æ˜¯ 0.6
    - â€œæ—©ä¸Šå¥½â€ çš„æ¦‚ç‡æ˜¯ 0.3
    - â€œå˜¿â€ çš„æ¦‚ç‡æ˜¯ 0.1
+ ç„¶åæ¨¡å‹**éšæœºæŠ½æ ·**ä¸€ä¸ªè¯å‡ºæ¥ï¼Œæ¯”å¦‚è¿™æ¬¡æŠ½åˆ°äº†â€œä½ å¥½â€

ğŸ‘‰ è¿™ä¸ªé‡‡æ ·ï¼ˆsamplingï¼‰æ“ä½œï¼Œæ˜¯**éå¯å¯¼ï¼ˆnon-differentiableï¼‰**çš„ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ ä¸èƒ½ç”¨æ¢¯åº¦å‘Šè¯‰æ¨¡å‹ï¼šâ€œä½ åˆšæ‰æŠ½å‡ºçš„æ˜¯ä¸ªä½åˆ†è¯ï¼Œä¸‹æ¬¡åˆ«æŠ½äº†ã€‚â€

å› ä¸ºâ€œæŠ½ç­¾â€è¿™ä¸ªè¿‡ç¨‹æ²¡æ³•å¾®è°ƒã€‚

æ‰€ä»¥éœ€è¦å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼šè¯­è¨€æ¨¡å‹æˆä¸ºâ€œæ™ºèƒ½ä½“â€ï¼ˆAgentï¼‰ï¼Œå°è¯•ä¸åŒçš„å›ç­”ï¼ˆåŠ¨ä½œï¼‰ï¼Œæ ¹æ®å¥–åŠ±æ¨¡å‹ç»™çš„åˆ†æ•°ï¼ˆå¥–åŠ±ï¼‰æ¥è°ƒæ•´ç­–ç•¥ï¼ˆå³ç”Ÿæˆå›ç­”çš„æ–¹å¼ï¼‰ã€‚



### DPO


## æ­å»ºLLaMA	
### RMSNorm
![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754725850218-e9317af6-a04f-4091-a310-6c5d51a69113.png)

æŠŠæ™®é€šLayerNormé™¤çš„æ–¹å·®å˜æˆäº†å¹³æ–¹å’Œçš„å‡å€¼ï¼Œå¹¶ä¸”å‡å°‘äº†å‡å»å‡å€¼è¿™ä¸€æ­¥ï¼ŒåŒæ—¶å‡å°‘äº†ä¸€ä¸ªåæ‰§ï¼Œå¯¹æ¯”ä¸‹NormLayer

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754904784418-dbbaa652-bcc8-4b14-b782-86b90c4dfa0f.png)

RMSNormæœ‰ä»€ä¹ˆä¼˜ç‚¹å‘¢ï¼Ÿ  
![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754904843913-d36ef87a-38dd-49c8-b234-06c829e62da6.png)

RMSnormä»£æ›¿äº†æ‰€æœ‰çš„LayerNormï¼Œå› ä¸ºè®ºæ–‡ä¸­**<font style="color:rgb(25, 27, 31);">è¿™æ ·å¤„ç†ä¹‹åï¼Œæ•´ä½“è®¡ç®—æ›´é«˜æ•ˆï¼Œæ¨¡å‹çš„è®­ç»ƒä¼šæ›´å¿«ã€‚</font>**<font style="color:rgb(25, 27, 31);">å¹¶ä¸”æ•ˆæœæ²¡æœ‰è·Œä¸‹æ¥å¤šå°‘</font>

æ­£å¥½åœ¨è¿™é‡Œå¯¹æ¯”ä¸€ä¸‹LayerNormå’ŒBatchNorm

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754902761599-72a3af2d-3f5c-437c-b099-8d86e31868ce.png)

åœ¨transformeré‡Œé¢ï¼Œä¸€ä¸ªbatchçš„ä¸åŒseqçš„lengthä¸ä¸€æ ·ï¼Œè¦ä¿æŒbatchä¸€è‡´å¾—å¯¹seq_lengthè¾ƒå°çš„è¿›è¡Œseqlengthå°ºåº¦ä¸‹çš„paddingï¼Œè¿™ç§ç±»ä¼¼ä¸‹å›¾

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1754901952380-5aca9ca5-de9e-47b8-942c-ea0af080a5da.png)

batchNormä¼šåŒ…å«äº†paddingï¼Œæ•ˆæœä¼šä¸å¥½ï¼ŒLayerNormå¯¹embeddingå°ºåº¦ä¸‹åšnormçš„è¯æ˜¯ä¸åŒ…å«paddidngçš„





### _init_weights(self, module):
å¯¹çº¿æ€§å±‚æŒ‰ç…§æ­£æ€åˆ†å¸ƒè¿›è¡Œåˆå§‹åŒ–

 ä»¥ä¸€ä¸ª `nn.Linear(in_features=4, out_features=3)` ä¸ºä¾‹ï¼Œå®ƒçš„ `weight` æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º `[3, 4]` çš„å¼ é‡ã€‚  

æ‰§è¡Œè¿™è¡Œä»£ç åï¼š

```python
torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
```

ä¼šå¯¹è¿™ä¸ª 3Ã—4 çš„çŸ©é˜µçš„ **æ¯ä¸ªå…ƒç´ **ï¼Œ**ç‹¬ç«‹åœ°**ä» `N(0, 0.02^2)` ä¸­é‡‡æ ·ã€‚  
 ä¹Ÿå°±æ˜¯æ¯ä¸ªinitialæ—¶å€™çš„çº¿æ€§å±‚éƒ½ä¼šåœ¨ä¸€ä¸ªæ­£å¤ªåˆ†å¸ƒé‡Œé‡‡æ ·ï¼Œä¸è¿‡åº”è¯¥å…ˆæ•ˆæœæ˜¯ä¸€æ ·çš„

åŒæ—¶å¯¹embeddingä¹Ÿè¿™æ ·ï¼Œå¯¹çº¿æ€§å±‚çš„biaså…¨èµ‹å€¼ä¸º0









### attention
<font style="color:rgb(25, 27, 31);">attentionæ·±åº¦è§£æï¼š  
</font>[https://zhuanlan.zhihu.com/p/626820422](https://zhuanlan.zhihu.com/p/626820422)

è¿™é‡Œçš„attentionè®¡ç®—æ˜¯GQA

![](https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/5-images/llama2-attention.png)

1. è¾“å…¥çš„æ•°æ®å¤§å°ä¸ºbatch_size, seq_len, dim
2. K,Q,Vä¸‰ä¸ªçŸ©é˜µå¤§å°ä¸º

self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)

self.wk = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)

        self.wv = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)

æ³¨æ„ä¸‰ä¸ªçŸ©é˜µçš„å¤§å°ä¸ä¸€è‡´ï¼Œkvæ˜¯ä¸€ä¸ªå¤§å°ï¼Œå¹¶ä¸”æ¯”è¾ƒå°ï¼Œé€šè¿‡çŸ©é˜µä¹‹åç›´æ¥æŠŠembedding dimå¤§å°å˜æˆhead*dimå¤§å°ï¼Œåé¢ä¼šæ‹†åˆ†æˆå¤šä¸ªå¤´

3. ä¹‹åç»™KQçŸ©é˜µåˆ©ç”¨posembeddingè¿›è¡Œæ—‹è½¬ï¼Œå…·ä½“ä»£ç çœ‹ä¹‹å‰çš„RoPE
4. å†å¯¹Kå’ŒVä¸¤ä¸ªçŸ©é˜µè¿›è¡Œrepeatï¼Œä»è€ŒåŒ¹é…query,ä¹‹åå°±å¯ä»¥è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—äº†ï¼Œrepeatä»£ç å¦‚ä¸‹ï¼š

```python
def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:
    # è·å–è¾“å…¥å¼ é‡çš„å½¢çŠ¶ï¼šæ‰¹é‡å¤§å°ã€åºåˆ—é•¿åº¦ã€é”®/å€¼å¯¹å¤´çš„æ•°é‡ã€æ¯ä¸ªå¤´çš„ç»´åº¦å¤§å°
    bs, slen, n_kv_heads, head_dim = x.shape
    
    # å¦‚æœé‡å¤æ¬¡æ•°ä¸º1ï¼Œåˆ™ä¸éœ€è¦é‡å¤ï¼Œç›´æ¥è¿”å›åŸå§‹å¼ é‡
    if n_rep == 1:
        return x
    
    # å¯¹å¼ é‡è¿›è¡Œæ‰©å±•å’Œé‡å¡‘æ“ä½œä»¥é‡å¤é”®å€¼å¯¹
    return (
        x[:, :, :, None, :]  # åœ¨ç¬¬å››ä¸ªç»´åº¦ï¼ˆå¤´çš„ç»´åº¦å‰ï¼‰æ·»åŠ ä¸€ä¸ªæ–°çš„ç»´åº¦
        .expand(bs, slen, n_kv_heads, n_rep, head_dim)  # å°†æ–°æ·»åŠ çš„ç»´åº¦æ‰©å±•åˆ°n_repå¤§å°ï¼Œå®ç°é‡å¤çš„æ•ˆæœ
        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)  # é‡æ–°å¡‘å½¢ï¼Œåˆå¹¶é”®/å€¼å¯¹å¤´çš„æ•°é‡å’Œé‡å¤æ¬¡æ•°çš„ç»´åº¦
    )
```

5. è®¡ç®—attentionmapï¼Œè¯¦è§ä¸‹é¢çš„attentionä¸­çš„forward  
 (batch,head,seq_l,dim)* (batch,head,dim,seq_l)è·å¾—æ³¨æ„åŠ›å›¾è°±(batch,head,seq_l,seq_l)ã€‚
6. ä¹‹åæ˜¯æ¯”è¾ƒéš¾ç†è§£çš„maskï¼Œä¸ºä»€ä¹ˆè¦åšmaskï¼Œä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ

**é¦–å…ˆæ˜ç¡®ä»¥ä¸‹ä¸ºä»€ä¹ˆè¦åšmaskï¼Œå› ä¸ºå¸Œæœ›åœ¨è®­ç»ƒçš„æ—¶å€™å¸Œæœ›ä¸€æ¬¡æ€§è®­ç»ƒä¸€æ•´å¥è¯(æ•°æ®å±‚é¢çš„ å¹¶è¡Œæ“ä½œï¼Œå¹¶ä¸æ˜¯ä¸€æ¬¡æ€§è¾“å‡ºæ‰€æœ‰çš„è¯­å¥ï¼‰**

æ¯”å¦‚è®­ç»ƒçš„æ—¶å€™è¾“å…¥çš„x,yæ˜¯ 

X: [BOS, T1, T2, T3, PAD] # è¾“å…¥

Y: [T1, T2, T3, PAD, PAD] # ç›®æ ‡ è®¨è®ºä¸‹xåœ¨è¿‡attentionæ¨¡å—çš„è¿‡ç¨‹ã€‚

æˆ‘ä»¬å¸Œæœ›ç»è¿‡maskä¹‹åè¾“å‡ºçš„attention mapå’Œvalueä¹˜ç§¯æ˜¯[batch,head,seq_length,dim]

å…¶ä¸­[:,:,0,:]è¿™ä¸€åˆ—æ•°æ®ç»§ç»­å¤„ç†ä¹‹åå’ŒT1åšloss,æŠŠ[:,:,1,:]è¿™ä¸€åˆ—æ•°æ®å¤„ç†ä¹‹åæ˜¯å’ŒT2åšlossçš„ï¼Œä¾æ¬¡ç±»æ¨ï¼Œä»è€Œåšåˆ°äº†æ¯æ¬¡è¾“å…¥æ¨¡å‹èƒ½å¤Ÿåœ¨æ¯ä¸ªbatchè®­ç»ƒä¸€æ•´å¥è¯,  è€Œä¸æ˜¯æ¯è¾“å…¥ä¸€ä¸ªå­—å’Œgroundtruthåšlossï¼Œä¹‹åå†æ·»åŠ å†è¾“å…¥ï¼Œè¿™æ˜¯æ¨ç†çš„æ—¶å€™å¹²çš„ï¼Œæ•ˆç‡ä¼šæ¯”è¾ƒä½

**æ¥ä¸‹æ¥è¯´æ˜ä¸‹ maskå‰åçš„æ­¥éª¤å¤§æ¦‚å¦‚ä¸‹**

    1. **è®¡ç®— Attention Scores  ä¹‹å å¼•å…¥ Maskï¼ˆå…³é”®é˜²å·çª¥ç¯èŠ‚ï¼‰  **

Mask çš„æœ¬è´¨ï¼š

        * åˆ›å»ºä¸€ä¸ªä¸ `<font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">scores</font>` åŒå½¢çŠ¶çš„çŸ©é˜µ `<font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">mask</font>`
        * å¯¹äºä¸å…è®¸è®¿é—®çš„ (t,s)(t, s)(t,s) ä½ç½®ï¼Œå¡«å……ä¸€ä¸ªæå¤§è´Ÿæ•°ï¼ˆä¾‹å¦‚ -1e9ï¼‰
        * å¯¹å…è®¸è®¿é—®çš„ä½ç½®å¡« 0

ä¾‹å¦‚ Causal Maskï¼ˆé˜²æ­¢çœ‹æœªæ¥ tokenï¼‰ï¼š

    2. **Softmax è½¬ä¸ºæ¦‚ç‡åˆ†å¸ƒ**

<font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">attn_weights</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">=</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">softmax</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">(</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">scores</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">masked</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">)</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">\text{attn\_weights} = \text{softmax}(\text{scores}_{\text{masked}})</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">attn_weights</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">=</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">softmax</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">(</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">scores</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">masked</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">)</font>

        * <font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">æ¯ä¸€è¡Œï¼ˆæ¯ä¸ª token å¯¹æ‰€æœ‰ token çš„æ³¨æ„åŠ›åˆ†å¸ƒï¼‰åªä¼šåœ¨å…è®¸çš„ä½ç½®æœ‰æ¦‚ç‡å€¼</font>
        * <font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">ç¦æ­¢çš„ä½ç½®æ¦‚ç‡ä¸¥æ ¼æ˜¯ 0</font>
        * <font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">ä»æ•°å­¦ä¸Šåˆ‡æ–­äº†è·å–æœªæ¥ token / padding token ä¿¡æ¯çš„è·¯å¾„</font>
    3. **åŠ æƒæ±‚å’Œï¼ˆä¿¡æ¯æµçš„ç‰©ç†å±è”½ï¼‰**

æœ€åç”¨æ³¨æ„åŠ›æƒé‡åŠ æƒ Vï¼š

outputt=âˆ‘s=1Lattn_weights[t,s]â‹…Vs\text{output}_t = \sum_{s=1}^{L} \text{attn\_weights}[t, s] \cdot V_soutputt=s=1âˆ‘Lattn_weights[t,s]â‹…Vs

        * å› ä¸ºç¦æ­¢çš„ s ä½ç½®æ¦‚ç‡æ˜¯ 0ï¼Œæ‰€ä»¥å®ƒä»¬çš„ V_s æ ¹æœ¬ä¸ä¼šè´¡çŒ®åˆ° output_t
        * **åœ¨æ•°æ®æµä¸Šå½»åº•é˜»æ–­äº†å·çª¥é€šé“**

**æ€»çš„æ¥è¯´ä»seqè¿™ä¸ªç»´åº¦çœ‹ï¼Œæ¯ä¸ªvå‘é‡çš„æƒé‡éƒ½åªå’Œå½“å‰å’Œå‰é¢æ‰€æœ‰çš„æƒé‡æœ‰å…³ï¼Œåšä¹˜ç§¯çš„æ—¶å€™éƒ½åªä¹˜äº†å‰é¢çš„æ³¨æ„åŠ›å›¾è°±ä¸Šçš„æƒé‡ï¼Œè¿™æ ·è¾“å‡ºå°±å®ç°äº†ç‰©ç†å±è”½ï¼Œæœ€ç»ˆçš„ç›®çš„æ˜¯ä¸ºäº†å¹¶è¡Œä¸€æ¬¡ç”¨ä¸€æ•´å¥è¯å®Œæˆè®­ç»ƒ**

7. æŠ•å½±å›ä¹‹å‰çš„ç»´åº¦

```python
        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)

        # æœ€ç»ˆæŠ•å½±å›æ®‹å·®æµã€‚
        output = self.wo(output)
        output = self.resid_dropout(output)
```

(batch,head,seq,head_dim)-(batch,seq,head*head_dim)

(batch,seq,head*head_dim)-(batch,seq,dim)_dropout

8. å®Œæ•´çš„ä»£ç å¦‚ä¸‹ï¼š

```python
class Attention(nn.Module):
    def __init__(self, args: ModelConfig):
        super().__init__()
        # æ ¹æ®æ˜¯å¦æŒ‡å®šn_kv_headsï¼Œç¡®å®šç”¨äºé”®ï¼ˆkeyï¼‰å’Œå€¼ï¼ˆvalueï¼‰çš„å¤´çš„æ•°é‡ã€‚
        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads
        # ç¡®ä¿æ€»å¤´æ•°å¯ä»¥è¢«é”®å€¼å¤´æ•°æ•´é™¤ã€‚
        assert args.n_heads % self.n_kv_heads == 0

        # æ¨¡å‹å¹¶è¡Œå¤„ç†å¤§å°ï¼Œé»˜è®¤ä¸º1ã€‚
        model_parallel_size = 1
        # æœ¬åœ°è®¡ç®—å¤´æ•°ï¼Œç­‰äºæ€»å¤´æ•°é™¤ä»¥æ¨¡å‹å¹¶è¡Œå¤„ç†å¤§å°ã€‚
        self.n_local_heads = args.n_heads // model_parallel_size
        # æœ¬åœ°é”®å€¼å¤´æ•°ï¼Œç­‰äºé”®å€¼å¤´æ•°é™¤ä»¥æ¨¡å‹å¹¶è¡Œå¤„ç†å¤§å°ã€‚
        self.n_local_kv_heads = self.n_kv_heads // model_parallel_size
        # é‡å¤æ¬¡æ•°ï¼Œç”¨äºæ‰©å±•é”®å’Œå€¼çš„å°ºå¯¸ã€‚
        self.n_rep = self.n_local_heads // self.n_local_kv_heads
        # æ¯ä¸ªå¤´çš„ç»´åº¦ï¼Œç­‰äºæ¨¡å‹ç»´åº¦é™¤ä»¥å¤´çš„æ€»æ•°ã€‚
        self.head_dim = args.dim // args.n_heads

        # å®šä¹‰æƒé‡çŸ©é˜µã€‚
        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)
        self.wk = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)
        self.wv = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)
        # è¾“å‡ºæƒé‡çŸ©é˜µã€‚
        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)

        # å®šä¹‰dropoutã€‚
        self.attn_dropout = nn.Dropout(args.dropout)
        self.resid_dropout = nn.Dropout(args.dropout)
        # ä¿å­˜dropoutæ¦‚ç‡ã€‚
        self.dropout = args.dropout

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨Flash Attentionï¼ˆéœ€è¦PyTorch >= 2.0ï¼‰ã€‚
        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')
        if not self.flash:
            # è‹¥ä¸æ”¯æŒFlash Attentionï¼Œåˆ™ä½¿ç”¨æ‰‹åŠ¨å®ç°çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶è®¾ç½®maskã€‚
            print("WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0")
            # åˆ›å»ºä¸€ä¸ªä¸Šä¸‰è§’çŸ©é˜µï¼Œç”¨äºé®è”½æœªæ¥ä¿¡æ¯ã€‚
            mask = torch.full((1, 1, args.max_seq_len, args.max_seq_len), float("-inf"))
            mask = torch.triu(mask, diagonal=1)
            # æ³¨å†Œä¸ºæ¨¡å‹çš„ç¼“å†²åŒº
            self.register_buffer("mask", mask)

    def forward(self, x: torch.Tensor, freqs_cos: torch.Tensor, freqs_sin: torch.Tensor):
        # è·å–æ‰¹æ¬¡å¤§å°å’Œåºåˆ—é•¿åº¦ï¼Œ[batch_size, seq_len, dim]
        bsz, seqlen, _ = x.shape

        # è®¡ç®—æŸ¥è¯¢ï¼ˆQï¼‰ã€é”®ï¼ˆKï¼‰ã€å€¼ï¼ˆVï¼‰ã€‚
        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)
        # è°ƒæ•´å½¢çŠ¶ä»¥é€‚åº”å¤´çš„ç»´åº¦ã€‚
        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)
        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)
        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)

        # åº”ç”¨æ—‹è½¬ä½ç½®åµŒå…¥ï¼ˆRoPEï¼‰ã€‚
        xq, xk = apply_rotary_emb(xq, xk, freqs_cos, freqs_sin)

        # å¯¹é”®å’Œå€¼è¿›è¡Œæ‰©å±•ä»¥é€‚åº”é‡å¤æ¬¡æ•°ã€‚
        xk = repeat_kv(xk, self.n_rep)
        xv = repeat_kv(xv, self.n_rep)

        # å°†å¤´ä½œä¸ºæ‰¹æ¬¡ç»´åº¦å¤„ç†ã€‚
        xq = xq.transpose(1, 2)# è½¬æ¢ä¸‹ç»´åº¦
        xk = xk.transpose(1, 2)
        xv = xv.transpose(1, 2)

        # æ ¹æ®æ˜¯å¦æ”¯æŒFlash Attentionï¼Œé€‰æ‹©å®ç°æ–¹å¼ã€‚
        if self.flash:
            # ä½¿ç”¨Flash Attentionã€‚
            output = torch.nn.functional.scaled_dot_product_attention(xq, xk, xv, attn_mask=None, dropout_p=self.dropout if self.training else 0.0, is_causal=True)
        else:
            # ä½¿ç”¨æ‰‹åŠ¨å®ç°çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚
            scores = torch.matmul(xq, xk.transpose(2, 3)) / math.sqrt(self.head_dim)
            assert hasattr(self, 'mask')
            scores = scores + self.mask[:, :, :seqlen, :seqlen]
            scores = F.softmax(scores.float(), dim=-1).type_as(xq)
            scores = self.attn_dropout(scores)
            output = torch.matmul(scores, xv)

        # æ¢å¤æ—¶é—´ç»´åº¦å¹¶åˆå¹¶å¤´ã€‚
        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)

        # æœ€ç»ˆæŠ•å½±å›æ®‹å·®æµã€‚
        output = self.wo(output)
        output = self.resid_dropout(output)
        return output
```

<font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);">  
</font><font style="color:rgb(82, 82, 82);background-color:rgb(248, 248, 248);"> </font>

### MLP
è¾“å…¥è¾“å‡ºçš„ç»´åº¦ä¸€è‡´ï¼Œ

(batch,seq,dim)-(batch,seq,dim)

æ‰©å¤§å†ç¼©å°ç½¢äº†

```python
class MLP(nn.Module):
    def __init__(self, dim: int, hidden_dim: int, multiple_of: int, dropout: float):
        super().__init__()
        # å¦‚æœæ²¡æœ‰æŒ‡å®šéšè—å±‚çš„ç»´åº¦ï¼Œæˆ‘ä»¬å°†å…¶è®¾ç½®ä¸ºè¾“å…¥ç»´åº¦çš„4å€
        # ç„¶åå°†å…¶å‡å°‘åˆ°2/3ï¼Œæœ€åç¡®ä¿å®ƒæ˜¯multiple_ofçš„å€æ•°
        if hidden_dim is None:
            hidden_dim = 4 * dim
            hidden_dim = int(2 * hidden_dim / 3)
            hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)
        # å®šä¹‰ç¬¬ä¸€å±‚çº¿æ€§å˜æ¢ï¼Œä»è¾“å…¥ç»´åº¦åˆ°éšè—ç»´åº¦
        self.w1 = nn.Linear(dim, hidden_dim, bias=False)
        # å®šä¹‰ç¬¬äºŒå±‚çº¿æ€§å˜æ¢ï¼Œä»éšè—ç»´åº¦åˆ°è¾“å…¥ç»´åº¦
        self.w2 = nn.Linear(hidden_dim, dim, bias=False)
        # å®šä¹‰ç¬¬ä¸‰å±‚çº¿æ€§å˜æ¢ï¼Œä»è¾“å…¥ç»´åº¦åˆ°éšè—ç»´åº¦
        self.w3 = nn.Linear(dim, hidden_dim, bias=False)
        # å®šä¹‰dropoutå±‚ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        # å‰å‘ä¼ æ’­å‡½æ•°
        # é¦–å…ˆï¼Œè¾“å…¥xé€šè¿‡ç¬¬ä¸€å±‚çº¿æ€§å˜æ¢å’ŒSILUæ¿€æ´»å‡½æ•°
        # ç„¶åï¼Œç»“æœä¹˜ä»¥è¾“å…¥xé€šè¿‡ç¬¬ä¸‰å±‚çº¿æ€§å˜æ¢çš„ç»“æœ
        # æœ€åï¼Œé€šè¿‡ç¬¬äºŒå±‚çº¿æ€§å˜æ¢å’Œdropoutå±‚
        return self.dropout(self.w2(F.silu(self.w1(x)) * self.w3(x)))
```

è¿™é‡Œè§£é‡Šä¸€ä¸‹MLPä¸­çš„ç»†èŠ‚ï¼šï¼š

é¦–å…ˆMLPä¸­ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°æ˜¯SiLUå‡½æ•°ï¼Œå¯ä»¥ç†è§£æˆbeta=1çš„Swishå‡½æ•°ï¼Œä¹Ÿå°±æ˜¯æ²¡æœ‰é—¨æ§çŸ©é˜µçš„swishå‡½æ•°

[https://docs.pytorch.ac.cn/docs/stable/generated/torch.nn.SiLU.html](https://docs.pytorch.ac.cn/docs/stable/generated/torch.nn.SiLU.html)

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759486914877-13cd71fa-df5f-4507-809e-97e409372cd3.png)  
 ![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759486924537-301fae1a-f975-4edc-8817-1a5fcdd301dd.png)

è¿™é‡Œè§£é‡Šä»¥ä¸‹Swishå‡½æ•°

[https://zhuanlan.zhihu.com/p/364620596](https://zhuanlan.zhihu.com/p/364620596)ï¼ˆåŒ…å«äº†æ¿€æ´»å‡½æ•°çš„å‘å±•å†ç¨‹ï¼Œæš—å«äº†ä¸ºä»€ä¹ˆç”¨swishå‡½æ•°æ¯”è¾ƒå¤šï¼‰

<font style="color:rgb(25, 27, 31);">Swishæ¿€æ´»å‡½æ•°åˆå«ä½œè‡ªé—¨æ§æ¿€æ´»å‡½æ•°ï¼Œå®ƒç”±è°·æ­Œçš„ç ”ç©¶è€…å‘å¸ƒï¼Œæ•°å­¦è¡¨è¾¾å¼ä¸ºï¼š</font>

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759486982039-6dd12c4c-ffad-4e7d-bcb5-9c8685dd6ac6.png)

<font style="color:rgb(25, 27, 31);">Î²ä¸ºå¯å­¦ä¹ çš„å‚æ•°æˆ–ä¸€ä¸ªå›ºå®šè¶…å‚æ•°ï¼Œ  å¯ä»¥çœ‹åšæ˜¯ä¸€ç§è½¯æ€§çš„é—¨æ§æœºåˆ¶ã€‚</font>

<font style="color:rgb(25, 27, 31);">å½“ Ïƒ(x)æ¥è¿‘äº1æ—¶ï¼Œé—¨å¤„äºâ€œ</font>**<font style="color:rgb(25, 27, 31);">å¼€</font>**<font style="color:rgb(25, 27, 31);">â€çŠ¶æ€ï¼Œæ¿€æ´»å‡½æ•°çš„è¾“å‡ºè¿‘ä¼¼äºxæœ¬èº«ï¼›</font>

<font style="color:rgb(25, 27, 31);">å½“ Ïƒ(x)æ¥è¿‘äº0æ—¶ï¼Œé—¨å¤„äºâ€œ</font>**<font style="color:rgb(25, 27, 31);">å…³</font>**<font style="color:rgb(25, 27, 31);">â€çŠ¶æ€ï¼Œæ¿€æ´»å‡½æ•°çš„è¾“å‡ºè¿‘ä¼¼äº0ï¼›</font>

<font style="color:rgb(25, 27, 31);">å› æ­¤ï¼Œ</font>**<font style="color:rgb(25, 27, 31);">Swish å‡½æ•°å¯ä»¥çœ‹ä½œçº¿æ€§å‡½æ•°å’ŒReLU å‡½æ•°ä¹‹é—´çš„éçº¿æ€§æ’å€¼å‡½æ•°</font>**<font style="color:rgb(25, 27, 31);">ï¼Œ</font>**<font style="color:rgb(25, 27, 31);">å…¶ç¨‹åº¦ç”±å‚æ•°  æ§åˆ¶ã€‚</font>**

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759487045556-71c3dbd7-57cf-4d8b-80f0-ef5f36c2d4ac.png)

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½¿ç”¨Swishæœ€é‡è¦çš„åŸå› ï¼Œé—¨æ§å‡½æ•°å¯ä»¥æ ¹æ®æƒ…å†µè‡ªå·±é€‰æ‹©ä½¿ç”¨ä»€ä¹ˆæ ·çš„æ¿€æ´»å‡½æ•°ï¼Œ  
å¯ä»¥æ˜¯Î²å¾ˆå¤§ï¼Œä¹Ÿå°±æ˜¯ReLUï¼Œé€‰æ‹©è¿™ä¸ªçš„æ—¶å€™å¯èƒ½ä¸ä¼šç¢°åˆ°ä»€ä¹ˆxå°äº0 çš„æƒ…å†µï¼Œ

å¯èƒ½æ˜¯Î²=0...



å®é™…ä¸Šçš„FFNä¸­ï¼Œè¾“å…¥è¿›SiLUçš„æ˜¯x*w_gateï¼Œä¹Ÿå°±æ˜¯è¯´é—¨æ§çŸ©é˜µæ˜¯æ‰‹åŠ¨è¾“å…¥çš„ï¼Œä¹Ÿå°±æ˜¯è¯´æ‰‹åŠ¨ä»SiLUå‡½æ•°å®ç°äº†Swishå‡½æ•°

åŒæ—¶ä¸swishä¸åŒçš„æ˜¯ï¼Œé—¨æ§çŸ©é˜µè¿˜å¯¹<font style="color:rgb(25, 27, 31);">Ïƒ(x)å¤–ä¹Ÿæœ‰ä½œç”¨ï¼Œä¹Ÿå°±æ˜¯Î²xÏƒ(Î²x)ï¼Œè¿™é‡Œå¯ä»¥ç†è§£æˆä¸€ä¸ªå®Œæ•´çš„æ¿€æ´»å‡½æ•°ï¼Œå¯¹åº”çš„ä»£ç æ˜¯ï¼š</font>

<font style="color:rgb(25, 27, 31);">F.silu(self.w1(x)ï¼‰</font>

<font style="color:rgb(25, 27, 31);">ä¹‹åå†å¯¹æ•´ä½“åšä¸ªç‚¹ä¹˜W1ï¼Œè¿™äº›éƒ½æ˜¯å‡é«˜ç»´åº¦çš„è¿‡ç¨‹</font>

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759487337098-9dfc36ab-b7a8-4909-93e5-75fb47425f43.png)

è¿™ä¸ªå°±æ˜¯æ•´ä½“æ¿€æ´»çš„è¿‡ç¨‹

### LLaMAæ€»ç»“æ„
æ ¹æ®ä¹‹å‰æåˆ°çš„æ­å»ºdecoder

```python
class DecoderLayer(nn.Module):
    def __init__(self, layer_id: int, args: ModelConfig):
        super().__init__()
        # å®šä¹‰å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°
        self.n_heads = args.n_heads
        # å®šä¹‰è¾“å…¥ç»´åº¦
        self.dim = args.dim
        # å®šä¹‰æ¯ä¸ªå¤´çš„ç»´åº¦ï¼Œç­‰äºè¾“å…¥ç»´åº¦é™¤ä»¥å¤´æ•°
        self.head_dim = args.dim // args.n_heads
        # å®šä¹‰LLaMA2Attentionå¯¹è±¡ï¼Œç”¨äºè¿›è¡Œå¤šå¤´æ³¨æ„åŠ›è®¡ç®—
        self.attention = Attention(args)
        # å®šä¹‰LLaMAMLPå¯¹è±¡ï¼Œç”¨äºè¿›è¡Œå‰é¦ˆç¥ç»ç½‘ç»œè®¡ç®—
        self.feed_forward = MLP(
            dim=args.dim,
            hidden_dim=args.hidden_dim,
            multiple_of=args.multiple_of,
            dropout=args.dropout,
        )
        # å®šä¹‰å±‚çš„ID
        self.layer_id = layer_id
        # å®šä¹‰æ³¨æ„åŠ›è®¡ç®—çš„å½’ä¸€åŒ–å±‚
        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)
        # å®šä¹‰å‰é¦ˆç¥ç»ç½‘ç»œè®¡ç®—çš„å½’ä¸€åŒ–å±‚
        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)

    def forward(self, x, freqs_cos, freqs_sin):
        # å‰å‘ä¼ æ’­å‡½æ•°
        # é¦–å…ˆï¼Œè¾“å…¥xç»è¿‡æ³¨æ„åŠ›å½’ä¸€åŒ–å±‚ï¼Œç„¶åè¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ï¼Œç»“æœä¸è¾“å…¥xç›¸åŠ å¾—åˆ°h
        # ç„¶åï¼Œhç»è¿‡å‰é¦ˆç¥ç»ç½‘ç»œå½’ä¸€åŒ–å±‚ï¼Œç„¶åè¿›è¡Œå‰é¦ˆç¥ç»ç½‘ç»œè®¡ç®—ï¼Œç»“æœä¸hç›¸åŠ å¾—åˆ°è¾“å‡º
        h = x + self.attention.forward(self.attention_norm(x), freqs_cos, freqs_sin)
        out = h + self.feed_forward.forward(self.ffn_norm(h))
        return out
```

  
 å†æ­å»ºllama

```python
class Transformer(PreTrainedModel):
    config_class = ModelConfig  # é…ç½®ç±»
    last_loss: Optional[torch.Tensor] # è®°å½•æœ€åä¸€æ¬¡è®¡ç®—çš„æŸå¤±

    def __init__(self, args: ModelConfig = None):
        super().__init__(args)
        # åˆå§‹åŒ–æ¨¡å‹å‚æ•°
        self.args = args
        # è¯æ±‡è¡¨å¤§å°
        self.vocab_size = args.vocab_size
        # å±‚æ•°
        self.n_layers = args.n_layers

        # è¯åµŒå…¥å±‚
        self.tok_embeddings = nn.Embedding(args.vocab_size, args.dim)
        # Dropoutå±‚
        self.dropout = nn.Dropout(args.dropout)
        # Decoderå±‚
        self.layers = torch.nn.ModuleList()
        for layer_id in range(args.n_layers):
            self.layers.append(DecoderLayer(layer_id, args))
        # å½’ä¸€åŒ–å±‚
        self.norm = RMSNorm(args.dim, eps=args.norm_eps)
        # è¾“å‡ºå±‚
        self.output = nn.Linear(args.dim, args.vocab_size, bias=False)

        # å°†è¯åµŒå…¥å±‚çš„æƒé‡ä¸è¾“å‡ºå±‚çš„æƒé‡å…±äº«
        self.tok_embeddings.weight = self.output.weight 

        # é¢„è®¡ç®—ç›¸å¯¹ä½ç½®åµŒå…¥çš„é¢‘ç‡
        freqs_cos, freqs_sin = precompute_freqs_cis(self.args.dim // self.args.n_heads, self.args.max_seq_len)
        self.register_buffer("freqs_cos", freqs_cos, persistent=False)
        self.register_buffer("freqs_sin", freqs_sin, persistent=False)

        # åˆå§‹åŒ–æ‰€æœ‰æƒé‡
        self.apply(self._init_weights)
        # å¯¹æ®‹å·®æŠ•å½±è¿›è¡Œç‰¹æ®Šçš„ç¼©æ”¾åˆå§‹åŒ–
        for pn, p in self.named_parameters():
            if pn.endswith('w3.weight') or pn.endswith('wo.weight'):
                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * args.n_layers))

        # åˆå§‹åŒ–æœ€åä¸€æ¬¡å‰å‘ä¼ æ’­çš„æŸå¤±å±æ€§
        self.last_loss = None
        self.OUT = CausalLMOutputWithPast()  # è¾“å‡ºå®¹å™¨
        self._no_split_modules = [name for name, _ in self.named_modules()]  # ä¸åˆ†å‰²çš„æ¨¡å—åˆ—è¡¨

    def _init_weights(self, module):
        # åˆå§‹åŒ–æƒé‡çš„å‡½æ•°
        if isinstance(module, nn.Linear):
            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
        elif isinstance(module, nn.Embedding):
            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
    
    def forward(self, tokens: torch.Tensor, targets: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor:
        """
        - tokens: Optional[torch.Tensor], è¾“å…¥ token å¼ é‡ã€‚
        - targets: Optional[torch.Tensor], ç›®æ ‡ token å¼ é‡ã€‚
        - kv_cache: bool, æ˜¯å¦ä½¿ç”¨é”®å€¼ç¼“å­˜ã€‚
        - kwargs: å…¶ä»–å…³é”®å­—å‚æ•°ã€‚

        - self.OUT: CausalLMOutputWithPast, åŒ…å« logits å’ŒæŸå¤±ã€‚
        """

        if 'input_ids' in kwargs:
            tokens = kwargs['input_ids']
        if 'attention_mask' in kwargs:
            targets = kwargs['attention_mask']

        # å‰å‘ä¼ æ’­å‡½æ•°
        _bsz, seqlen = tokens.shape
        # é€šè¿‡è¯åµŒå…¥å±‚å’ŒDropoutå±‚
        h = self.tok_embeddings(tokens)
        h = self.dropout(h)
        # è·å–ç›¸å¯¹ä½ç½®åµŒå…¥çš„é¢‘ç‡
        freqs_cos = self.freqs_cos[:seqlen]
        freqs_sin = self.freqs_sin[:seqlen]

        # é€šè¿‡Decoderå±‚
        for layer in self.layers:
            h = layer(h, freqs_cos, freqs_sin)
        # é€šè¿‡å½’ä¸€åŒ–å±‚
        h = self.norm(h)

        if targets is not None:
            # å¦‚æœç»™å®šäº†ç›®æ ‡ï¼Œè®¡ç®—æŸå¤±
            logits = self.output(h)
            self.last_loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=0, reduction='none')
        else: 
            # åªå¯¹æœ€åä¸€ä¸ªä½ç½®çš„è¾“å‡ºè¿›è¡Œå‰å‘ä¼ æ’­ï¼Œæ¨ç†è¿‡ç¨‹èµ°è¿™è¾¹
            logits = self.output(h[:, [-1], :]) 
            self.last_loss = None

        # è®¾ç½®è¾“å‡º
        self.OUT.__setitem__('logits', logits)
        self.OUT.__setitem__('last_loss', self.last_loss)
        return self.OUT

```

### æ¨ç†è¿‡ç¨‹ï¼š
#### å¤„ç†è¾“å…¥æ•°æ®
    1. æˆªæ–­

#### è·å¾—è¯è¡¨æ¦‚ç‡
```python
logits = self(idx_cond).logits # è¿™é‡Œselfå°±æ˜¯å‰å‘ä¼ æ’­ï¼Œè¾“å‡ºçš„logitså½¢å¼ä¸º(batch_size, seq_len, vocab_size)
logits = logits[:, -1, :] # åªä¿ç•™æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºï¼Œç”¨æ¥è·å¾—ä¸‹ä¸€ä¸ªtoken
```

#### æŒ‘é€‰è¾“å‡ºtoken 
```python
if temperature == 0.0:
     # é€‰æ‹©æœ€æœ‰å¯èƒ½çš„ç´¢å¼•
    _, idx_next = torch.topk(logits, k=1, dim=-1)#è´ªå¿ƒç­–ç•¥ï¼Œç›´æ¥é€‰æ¦‚ç‡æœ€é«˜çš„ token id
else:
    # ç¼©æ”¾ logits å¹¶åº”ç”¨ softmax
    logits = logits / temperature
    if top_k is not None:
        v, _ = torch.topk(logits, min(top_k, logits.size(-1)))
        logits[logits < v[:, [-1]]] = -float('Inf')
    probs = F.softmax(logits, dim=-1)
    idx_next = torch.multinomial(probs, num_samples=1)
```

##### è´ªå¿ƒç­–ç•¥
ç›´æ¥é€‰æ¦‚ç‡æœ€é«˜çš„ï¼Œéšæœºæ€§ä½ï¼Œè¡¨è¾¾åŠ›å¼±

##### æ¸©åº¦ç¼©æ”¾é‡‡æ ·ç­–ç•¥ï¼ˆTemperature Scaling Samplingï¼‰  
1. èƒŒæ™¯ï¼šä¸ºä»€ä¹ˆè¦æ¸©åº¦ç¼©æ”¾ï¼Ÿ

åœ¨ç”Ÿæˆæ¨¡å‹é‡Œï¼Œæ¯”å¦‚ GPTï¼Œä½ ä¼šå¾—åˆ°ä¸€ä¸ªé¢„æµ‹æ¦‚ç‡åˆ†å¸ƒï¼š

```plain
rust


å¤åˆ¶ç¼–è¾‘
logits -> softmax -> æ¦‚ç‡åˆ†å¸ƒ P
```

å¦‚æœæˆ‘ä»¬ç›´æ¥é€‰æ¦‚ç‡æœ€å¤§çš„ tokenï¼ˆè´ªå¿ƒç­–ç•¥ï¼‰ï¼Œç”Ÿæˆç»“æœä¼šï¼š

    - éå¸¸ç¡®å®šï¼Œä½†**ç¼ºä¹å¤šæ ·æ€§**ï¼Œå®¹æ˜“é‡å¤
    - å¯¹ä½æ¦‚ç‡é€‰é¡¹å‡ ä¹æ²¡æœ‰æ¢ç´¢

å¦‚æœæˆ‘ä»¬ç›´æ¥æŒ‰åŸå§‹æ¦‚ç‡åˆ†å¸ƒéšæœºé‡‡æ ·ï¼š

    - å¤šæ ·æ€§é«˜
    - ä½†å®¹æ˜“å‡ºç°ä½è´¨é‡æˆ–è¯­ä¹‰è·³è·ƒçš„ç»“æœ

**æ¸©åº¦ç¼©æ”¾** å°±æ˜¯ç”¨ä¸€ä¸ªç³»æ•° **Tï¼ˆTemperatureï¼‰** æ¥è°ƒèŠ‚è¿™ä¸ªéšæœºæ€§ã€‚

2. å…¬å¼

å‡è®¾åŸå§‹ logits ä¸º ziï¼Œsoftmax å…¬å¼æ˜¯ï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1755098137734-2f72f992-e166-471e-b8d5-36e68e66cbda.png)

åŠ å…¥æ¸©åº¦ Tï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1755098153001-af3ea48c-2d67-472e-a2f5-c3fa3c353a96.png)

    - **T < 1**ï¼šåˆ†å¸ƒå˜å¾—æ›´å°–é” â†’ æ›´ç¡®å®š â†’ æ¥è¿‘è´ªå¿ƒ
    - **T > 1**ï¼šåˆ†å¸ƒå˜å¾—æ›´å¹³æ»‘ â†’ æ›´éšæœº â†’ å¤šæ ·æ€§æå‡
    - **T â†’ 0**ï¼šæç«¯è´ªå¿ƒï¼ˆç›´æ¥å–æœ€å¤§å€¼ï¼‰
    - **T â†’ âˆ**ï¼šå‡ ä¹å‡åŒ€éšæœº
3. æ•ˆæœç¤ºæ„

å‡è®¾ logits = `[5.0, 2.0, 1.0]`  
softmax(T=1) â†’ æ¦‚ç‡åˆ†å¸ƒï¼š

```plain
csharp


å¤åˆ¶ç¼–è¾‘
[0.84, 0.11, 0.05]
```

    - **T = 0.5**ï¼ˆé™ä½æ¸©åº¦ï¼‰ï¼š

```plain
nginx


å¤åˆ¶ç¼–è¾‘
logits / 0.5 = [10, 4, 2]
softmax â†’ [0.97, 0.02, 0.01]
```

åˆ†å¸ƒæ›´å°–é”ï¼Œå‡ ä¹å¿…é€‰ç¬¬ä¸€ä¸ª tokenã€‚

    - **T = 2.0**ï¼ˆå‡é«˜æ¸©åº¦ï¼‰ï¼š

```plain
nginx


å¤åˆ¶ç¼–è¾‘
logits / 2 = [2.5, 1.0, 0.5]
softmax â†’ [0.62, 0.23, 0.15]
```

åˆ†å¸ƒæ›´å¹³æ»‘ï¼Œç¬¬äºŒã€ç¬¬ä¸‰ä¸ª token ä¹Ÿæœ‰æ›´å¤§æ¦‚ç‡è¢«é€‰åˆ°ã€‚

4. åœ¨é‡‡æ ·é‡Œçš„ä½œç”¨

æ¸©åº¦ç¼©æ”¾é€šå¸¸ä¸**éšæœºé‡‡æ ·**ï¼ˆmultinomialï¼‰æˆ–**Top-k/Top-p ç­–ç•¥**ç»“åˆä½¿ç”¨ï¼š

    1. æ¨¡å‹è¾“å‡º logits
    2. **é™¤ä»¥æ¸©åº¦ T**
    3. è¿›è¡Œ softmax å¾—åˆ°æ¦‚ç‡
    4. å†éšæœºæŠ½æ ·ä¸€ä¸ª token ä½œä¸ºä¸‹ä¸€ä¸ªç”Ÿæˆçš„ token

è¿™æ ·ï¼š

    - T å° â†’ æ¨¡å‹æ›´ä¿å®ˆï¼Œç”Ÿæˆç»“æœæ›´ç¨³å®šã€é‡å¤æ€§é«˜
    - T å¤§ â†’ æ¨¡å‹æ›´å¼€æ”¾ï¼Œç”Ÿæˆå¤šæ ·æ€§æ›´é«˜

è¯¦è§[https://zhuanlan.zhihu.com/p/1899617450024235966](https://zhuanlan.zhihu.com/p/1899617450024235966)

#### è¿”å›token 
```python
     # å°†é‡‡æ ·çš„ç´¢å¼•æ·»åŠ åˆ°åºåˆ—ä¸­å¹¶ç»§ç»­
        idx = torch.cat((idx, idx_next), dim=1)

        return idx[:, index:] # åªè¿”å›ç”Ÿæˆçš„token
```

indexæ˜¯è¾“å…¥çš„é—®é¢˜é•¿åº¦ï¼Œgenerateåœ¨max_new_tokensä¸‹å¾ªç¯ç”Ÿæˆçš„æ‰€æœ‰tokençš„é•¿åº¦å°±æ˜¯index:ä¹‹åçš„éƒ¨åˆ†ï¼Œè¿”å›è¿™äº›éƒ¨åˆ†



#### æ€»ä»£ç 
```python
@torch.inference_mode()
    def generate(self, idx, stop_id=None, max_new_tokens=256, temperature=1.0, top_k=None):
        """
        ç»™å®šè¾“å…¥åºåˆ— idxï¼ˆå½¢çŠ¶ä¸º (bz,seq_len) çš„é•¿æ•´å‹å¼ é‡ï¼‰ï¼Œé€šè¿‡å¤šæ¬¡ç”Ÿæˆæ–° token æ¥å®Œæˆåºåˆ—ã€‚
        åœ¨ model.eval() æ¨¡å¼ä¸‹è¿è¡Œã€‚æ•ˆç‡è¾ƒä½çš„é‡‡æ ·ç‰ˆæœ¬ï¼Œæ²¡æœ‰ä½¿ç”¨é”®k/v cacheã€‚
        """
        index = idx.shape[1]
        for _ in range(max_new_tokens):
            # å¦‚æœåºåˆ—ä¸Šä¸‹æ–‡è¿‡é•¿ï¼Œæˆªæ–­å®ƒåˆ°æœ€å¤§é•¿åº¦
            idx_cond = idx if idx.size(1) <= self.args.max_seq_len else idx[:, -self.args.max_seq_len:]
            
            # å‰å‘ä¼ æ’­è·å–åºåˆ—ä¸­æœ€åä¸€ä¸ªä½ç½®çš„ logits
            logits = self(idx_cond).logits # è¿™é‡Œselfå°±æ˜¯å‰å‘ä¼ æ’­ï¼Œè¾“å‡ºçš„logitså½¢å¼ä¸º(batch_size, seq_len, vocab_size)
            logits = logits[:, -1, :] # åªä¿ç•™æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºï¼Œç”¨æ¥è·å¾—ä¸‹ä¸€ä¸ªtoken
            
            if temperature == 0.0:
                # é€‰æ‹©æœ€æœ‰å¯èƒ½çš„ç´¢å¼•
                _, idx_next = torch.topk(logits, k=1, dim=-1)#è´ªå¿ƒç­–ç•¥ï¼Œç›´æ¥é€‰æ¦‚ç‡æœ€é«˜çš„ token id
            else:
                # ç¼©æ”¾ logits å¹¶åº”ç”¨ softmax
                logits = logits / temperature
                if top_k is not None:
                    v, _ = torch.topk(logits, min(top_k, logits.size(-1)))
                    logits[logits < v[:, [-1]]] = -float('Inf')
                probs = F.softmax(logits, dim=-1)
                idx_next = torch.multinomial(probs, num_samples=1)
            

            if idx_next == stop_id:
                break

            # å°†é‡‡æ ·çš„ç´¢å¼•æ·»åŠ åˆ°åºåˆ—ä¸­å¹¶ç»§ç»­
            idx = torch.cat((idx, idx_next), dim=1)

        return idx[:, index:] # åªè¿”å›ç”Ÿæˆçš„token
```

  
 

### é¢„è®­ç»ƒéƒ¨åˆ† 
```python
input_id:  [BOS, T1, T2, T3, PAD, PAD]
X:         [BOS, T1, T2, T3, PAD]   # è¾“å…¥
Y:         [T1,  T2, T3, PAD, PAD]  # ç›®æ ‡
mask:      [1,    1,  1,   0,   0]
```

è¾“å…¥çš„æ•°æ®å°±æ˜¯Xï¼Œ

ä»LLaMAè¾“å‡º[1,1,vocab_size]å°±æ˜¯è¯è¡¨å„ä¸ªå•è¯å‡ºç°çš„æ¦‚ç‡

è€ŒYå°±æ˜¯ç»™å®šçš„groundtruth

è¾“å…¥T1å’ŒBos(gt)åšlossï¼Œt2å’Œt1åšlossä¹‹åä¼šè·å¾—ç±»ä¼¼ä»¥ä¸‹ç»“æœ

```python
loss:
[
 [0.2, 0.1, 0.3, 0.05, 0.02],
]

```

å¾—åˆ°æ¯ä¸ªè®¡ç®—lossçš„è¿‡ç¨‹å°±æ˜¯åˆ©ç”¨äº¤å‰ç†µMSE

å’Œgroundtruthå¯ä»¥è®¡ç®—äº¤å‰ç†µï¼Œè¿‡ç¨‹å¤§æ¦‚å¦‚ä¸‹

å‡è®¾è¯è¡¨å¤§å° V=5ï¼Œ  
çœŸå®ç›®æ ‡ token æ˜¯ `T1`ï¼ˆç´¢å¼• 1ï¼‰ï¼ŒçœŸå®åˆ†å¸ƒæ˜¯ï¼š

q=[0,1,0,0,0]

æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡åˆ†å¸ƒï¼š

p=[0.05,0.70,0.20,0.03,0.02]

äº¤å‰ç†µå…¬å¼ï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1755186298975-060ed82f-4299-4573-bb8c-c9197d0c1690.png)

å› ä¸ºq æ˜¯ one-hotï¼Œåªæœ‰ç›®æ ‡ token ä½ç½®æ˜¯ 1ï¼Œæ‰€ä»¥å…¬å¼ç®€åŒ–ä¸ºï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1755186348570-ffc9b284-4452-4774-ae5b-74b5c689fc57.png)

åœ¨ä¾‹å­ä¸­ï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1755186365700-af703ad5-fdb7-4d6b-bdc5-8d8762818402.png)

æœ€ç»ˆå†å¯¹lossåšmaskæ±‚å’Œï¼Œå†å¯¹batchæ±‚å’Œï¼Œå°±æ˜¯ä¸€æ•´ä¸ªbatchçš„loss

åœ¨ä»£ç ä¸­ä½“ç°å¦‚ä¸‹ï¼š

```python
       if targets is not None:
            # å¦‚æœç»™å®šäº†ç›®æ ‡ï¼Œè®¡ç®—æŸå¤±
            logits = self.output(h)
            self.last_loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target
```

### SFT
æ„Ÿè§‰åªæœ‰maskä¸ä¸€æ ·ï¼ŒSFTçš„maskè¿‡ç¨‹å¦‚ä¸‹ï¼š  
![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1755188116513-b7a16a2b-b519-4849-900b-1e228bbe0922.png)

ä¹Ÿæ˜¯è¾“å…¥ä¸€æ•´æ®µæ–‡æœ¬è®¡ç®—lossï¼Œä¸è¿‡åªæŠŠæ ‡è®°ä¸º Assistant  éƒ¨åˆ†çš„æ–‡æœ¬ä¹‹å¤–çš„å…¶ä»–éƒ¨åˆ†å…¨éƒ¨maskæ‰ï¼ŒæŒ‡è®¡ç®—è¯¥éƒ¨åˆ†çš„loss

### ä½¿ç”¨Transformeræ­å»ºæ¨¡å‹å¹¶ç”¨Deepspeedå¹¶è¡Œè®­ç»ƒ
#### ä¸‹è½½é…ç½®æ–‡ä»¶å’Œæƒé‡æ¨¡å‹
```python
import os
# è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œæ­¤å¤„ä½¿ç”¨ HuggingFace é•œåƒç½‘ç«™
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
# ä¸‹è½½æ¨¡å‹
os.system('huggingface-cli download --resume-download Qwen/Qwen2.5-1.5B --local-dir your_local_dir')
```

#### åŠ è½½é…ç½®æ–‡ä»¶å’Œæ¨¡å‹
```python
# åŠ è½½å®šä¹‰å¥½çš„æ¨¡å‹å‚æ•°-æ­¤å¤„ä»¥ Qwen-2.5-1.5B ä¸ºä¾‹
# ä½¿ç”¨ transforemrs çš„ Config ç±»è¿›è¡ŒåŠ è½½
from transformers import AutoConfig

# ä¸‹è½½å‚æ•°çš„æœ¬åœ°è·¯å¾„
model_path = "qwen-1.5b"
config = AutoConfig.from_pretrained(model_name_or_path)
```

å…¶ä¸­ï¼ŒAutoConfigä½œç”¨å¦‚ä¸‹ï¼š  
`AutoConfig.from_pretrained(...)`

+ **ä½œç”¨**ï¼šåªåŠ è½½**æ¨¡å‹çš„é…ç½®æ–‡ä»¶**ï¼ˆconfig.json é‡Œçš„ä¿¡æ¯ï¼‰ï¼Œä¾‹å¦‚ï¼š
    - æ¨¡å‹çš„å±‚æ•°ã€éšè—ç»´åº¦ã€æ³¨æ„åŠ›å¤´æ•°ã€è¯è¡¨å¤§å°ç­‰è¶…å‚æ•°ã€‚
    - è¿˜æœ‰ tokenizer ç›¸å…³çš„ä¸€äº›é…ç½®ï¼ˆä½†ä¸åŠ è½½ tokenizer æœ¬èº«ï¼‰ã€‚
+ **ä¸ä¼šåŠ è½½æ¨¡å‹çš„å‚æ•°ï¼ˆæƒé‡ï¼‰**ï¼Œåªæ˜¯ä¸€ä¸ªâ€œç»“æ„è“å›¾â€ã€‚
+ å…¸å‹ç”¨æ³•ï¼š
+ å…·ä½“åŠ è½½configçš„æ–¹å¼ï¼š
    - **å¦‚æœæ˜¯æœ¬åœ°ç›®å½•**
        * å®ƒå°±ä¼šç›´æ¥åœ¨è¿™ä¸ªç›®å½•ä¸‹æ‰¾ `config.json`ã€‚
        * å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°±ä¼šæŠ¥é”™ï¼š`OSError: Can't load config for ...`ã€‚
+ **å¦‚æœä¸æ˜¯æœ¬åœ°ç›®å½•**ï¼ˆæ¯”å¦‚æ‹¼é”™è·¯å¾„ï¼Œæˆ–è€…ç›®å½•ä¸å­˜åœ¨ï¼‰
    - ğŸ¤— Transformers ä¼šæŠŠä½ ä¼ çš„å­—ç¬¦ä¸²å½“ä½œ **Hugging Face Hub ä¸Šçš„ä»“åº“ ID**ã€‚
    - ç”¨ **æ­£ç¡®çš„ repo åå­—**ï¼Œæ¯”å¦‚ï¼š

```plain
config = AutoConfig.from_pretrained("Qwen/Qwen-1.5B")
```

å¦‚æœæ¨¡å‹æ˜¯ gated/privateï¼Œè¿˜å¾—å…ˆï¼š

```plain
huggingface-cli login
```

ç„¶ååŠ è½½æ—¶ `transformers` ä¼šè‡ªåŠ¨å¸¦ä¸Šä½ çš„ tokenã€‚

#### åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æ¨¡å‹
ä¹‹ååˆ©ç”¨configåˆ›å»ºæ¨¡å‹ï¼ˆä½†æ˜¯å¹¶æ²¡æœ‰åŠ è½½å‚æ•°ï¼‰

```python
# ä½¿ç”¨è¯¥é…ç½®ç”Ÿæˆä¸€ä¸ªå®šä¹‰å¥½çš„æ¨¡å‹
from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_config(config,trust_remote_code=True)
```

`AutoModelForCausalLM.from_config(config, trust_remote_code=True)`

+ **ä½œç”¨**ï¼šæ ¹æ®ä¼ å…¥çš„ **é…ç½®å¯¹è±¡ (**`**config**`**)****åˆ›å»ºæ¨¡å‹ç»“æ„**ï¼Œä½†æ˜¯ï¼š
    - **ä¸ä¼šåŠ è½½é¢„è®­ç»ƒå¥½çš„å‚æ•°**ï¼ˆæ­¤æ—¶æƒé‡æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼‰ã€‚
    - åªæ˜¯æŒ‰ç…§ config æ­å»ºä¸€ä¸ªâ€œç©ºç™½æ¨¡å‹â€ã€‚

æ¨ªå‘å¯¹æ¯”ä¸€ä¸‹ï¼š`AutoModelForCausalLM` å…¶å®æ˜¯ ğŸ¤— Transformers æä¾›çš„ **â€œAuto ç±»â€** ä¹‹ä¸€ï¼Œç”¨æ¥æ ¹æ® `config.model_type` è‡ªåŠ¨åŒ¹é…åˆé€‚çš„æ¨¡å‹å®ç°ã€‚  ä¸åŒçš„Autoæ¨¡å‹ä»»åŠ¡å¤´ä¸ä¸€æ ·

| ç±»å | ä½œç”¨ | å…¸å‹åº”ç”¨åœºæ™¯ |
| --- | --- | --- |
| **AutoModel** | åªåŠ è½½â€œè£¸â€æ¨¡å‹ï¼ˆæ²¡æœ‰ä»»åŠ¡å¤´ï¼‰ï¼Œå³åŸºç¡€ Transformer ç¼–ç å™¨/è§£ç å™¨ã€‚ | è·å– hidden statesï¼Œåš embeddingï¼Œfine-tune è‡ªå®šä¹‰ä»»åŠ¡ã€‚ |
| **AutoModelForCausalLM** | è‡ªå›å½’è¯­è¨€å»ºæ¨¡ï¼ˆå·¦åˆ°å³é¢„æµ‹ï¼‰ï¼Œå…¸å‹ GPT ç³»åˆ—ã€‚ | ChatGPTã€Qwenã€LLaMA è¿™ç§ç”Ÿæˆä»»åŠ¡ã€‚ |
| **AutoModelForMaskedLM** | æ©ç è¯­è¨€å»ºæ¨¡ï¼ˆBERT ç±»ï¼‰ã€‚ | MLM é¢„è®­ç»ƒï¼Œå¡«ç©ºã€‚ |
| **AutoModelForSeq2SeqLM** | åºåˆ—åˆ°åºåˆ—ç”Ÿæˆï¼ˆç¼–ç å™¨-è§£ç å™¨ï¼‰ã€‚ | ç¿»è¯‘ã€æ‘˜è¦ã€T5/BART ç­‰ã€‚ |
| **AutoModelForSequenceClassification** | æ–‡æœ¬åˆ†ç±»ï¼ˆå¥å­çº§åˆ«ï¼‰ã€‚ | æƒ…æ„Ÿåˆ†æã€æ„å›¾åˆ†ç±»ã€‚ |
| **AutoModelForTokenClassification** | åºåˆ—æ ‡æ³¨ã€‚ | NERï¼ˆå‘½åå®ä½“è¯†åˆ«ï¼‰ã€POS æ ‡æ³¨ã€‚ |
| **AutoModelForQuestionAnswering** | æŠ½å–å¼é—®ç­”ã€‚ | SQuADã€é˜…è¯»ç†è§£ã€‚ |
| **AutoModelForMultipleChoice** | å¤šé€‰é¢˜ä»»åŠ¡ã€‚ | RACE æ•°æ®é›†ã€‚ |
| **AutoModelForVision2Seq** | å›¾åƒåˆ°æ–‡æœ¬ç”Ÿæˆã€‚ | Image Captioningï¼ˆBLIP-2ï¼‰ã€‚ |
| **AutoModelForImageClassification** | å›¾åƒåˆ†ç±»ã€‚ | ViT, ResNetã€‚ |
| **AutoModelForObjectDetection** | ç›®æ ‡æ£€æµ‹ã€‚ | DETR, YOLOSã€‚ |
| **AutoModelForSemanticSegmentation** | è¯­ä¹‰åˆ†å‰²ã€‚ | SegFormerã€‚ |
| **AutoModelForSpeechSeq2Seq** | è¯­éŸ³åˆ°æ–‡æœ¬ã€‚ | Whisperã€‚ |
| **AutoModelForAudioClassification** | éŸ³é¢‘åˆ†ç±»ã€‚ | Wav2Vec2, Hubertã€‚ |


 ä»»åŠ¡å¤´æŒ‡çš„æ˜¯åœ¨ **åŸºç¡€æ¨¡å‹ï¼ˆbackbone / encoder-decoderï¼‰** çš„æœ€åï¼Œå†æ¥ä¸€ä¸ª **é¢å¤–çš„å°å±‚ï¼ˆä¸€èˆ¬æ˜¯çº¿æ€§å±‚ + softmax / sigmoid ç­‰ï¼‰**ï¼Œä¸“é—¨é’ˆå¯¹æŸä¸ªä»»åŠ¡è¾“å‡ºç»“æœã€‚  

```python
  # é€šè¿‡Decoderå±‚
        for layer in self.layers:
            h = layer(h, freqs_cos, freqs_sin)
        # é€šè¿‡å½’ä¸€åŒ–å±‚
        h = self.norm(h)

        if targets is not None:
            # å¦‚æœç»™å®šäº†ç›®æ ‡ï¼Œè®¡ç®—æŸå¤±
            logits = self.output(h)
            self.last_loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=0, reduction='none')
        else: 
            # åªå¯¹æœ€åä¸€ä¸ªä½ç½®çš„è¾“å‡ºè¿›è¡Œå‰å‘ä¼ æ’­ï¼Œæ¨ç†è¿‡ç¨‹èµ°è¿™è¾¹
            logits = self.output(h[:, [-1], :]) 
            self.last_loss = None

        # è®¾ç½®è¾“å‡º
        self.OUT.__setitem__('logits', logits)
        self.OUT.__setitem__('last_loss', self.last_loss)
        return self.OUT

```

åŠ è½½æ¨¡å‹ï¼Œç›´æ¥from_pretrainedå°±å¯ä»¥äº†

```python
from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(model_name_or_path,trust_remote_code=True)
```

ä¹‹ååŠ è½½tokenizer

```python
# åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„ tokenizer
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)
```

  
 

## æ­å»ºminimind
### ç¯å¢ƒæ­å»º
### æ¨¡å‹ç»“æ„
### æ¨¡å‹è®­ç»ƒï¼š
ä½¿ç”¨æ¡†æ¶è®­ä¸€ä¸‹

### 
## <font style="color:rgb(31, 35, 40);">MoE</font>
MoEçš„å¥½å¤„æ˜¯ï¼šåœ¨ç›¸åŒçš„é¢„è®­ç»ƒ<font style="color:rgb(25, 27, 31);">åœ¨ç›¸åŒçš„è®¡ç®—é¢„ç®—æ¡ä»¶ä¸‹ï¼Œæ‚¨å¯ä»¥æ˜¾è‘—æ‰©å¤§æ¨¡å‹æˆ–æ•°æ®é›†çš„è§„æ¨¡ã€‚ç‰¹åˆ«æ˜¯åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œä¸ç¨ å¯†æ¨¡å‹ç›¸æ¯”ï¼Œæ··åˆä¸“å®¶æ¨¡å‹é€šå¸¸èƒ½å¤Ÿæ›´å¿«åœ°è¾¾åˆ°ç›¸åŒçš„è´¨é‡æ°´å¹³ã€‚  
</font><font style="color:rgb(25, 27, 31);">ç¿»è¯‘æˆäººè¯å°±æ˜¯ï¼Œç”±äºscaling lawï¼Œæ¨¡å‹è‚¯å®šè¶Šå¤§è¶Šå¥½ï¼ŒMoEå¯ä»¥åœ¨è®¡ç®—èµ„æºä¸€å®šçš„æƒ…å†µä¸‹æ‰©å¤§æ¨¡å‹çš„å¤§å°ï¼Œä»è€Œæ‰©å¤§æ¨¡å‹çš„è¡¨ç°èƒ½åŠ›ã€‚</font>

<font style="color:rgb(25, 27, 31);">MoEåŸºç¡€ç»“æ„ï¼š</font>

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759235701623-eb26b7f8-46d3-47b8-bbcf-157cf3deded8.png)

å¤šäº†ä¸ªMoEå±‚ï¼Œåˆè·¯ç”±å’Œå¤šä¸ªffnæ¥ç»„æˆï¼Œè·¯ç”±æ¥å†³å®šä½¿ç”¨ä»€ä¹ˆffn

å› ä¸ºæ¯æ¬¡è°ƒç”¨çš„æ˜¯å…¶ä¸­å‡ ä¸ªä¸“å®¶æ¨¡å‹ï¼ˆffnï¼‰ä½œä¸ºè¾“å‡ºç”¨ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿç§°è¿™æ ·çš„æ¨¡å‹æ˜¯ç¨€ç–çš„ï¼Œè¿™æ ·ä¼šæœ‰å¾ˆå¤šé—®é¢˜ï¼š

1. è·¯ç”±åˆ†é…ä¸å‡é—®é¢˜

<font style="color:rgb(25, 27, 31);">æ¯”å¦‚è¯´è¾“å…¥10 ä¸ªtokenï¼Œ </font>**<font style="color:rgb(25, 27, 31);">å¯èƒ½ä¼šæœ‰äº”ä¸ªä»¤ç‰Œè¢«è·¯ç”±åˆ°åŒä¸€ä¸ªä¸“å®¶ï¼Œè€Œå‰©ä¸‹çš„äº”ä¸ªä»¤ç‰Œåˆ†åˆ«è¢«è·¯ç”±åˆ°ä¸åŒçš„ä¸“å®¶ã€‚è¿™å¯¼è‡´äº†æ‰¹é‡å¤§å°çš„ä¸å‡åŒ€åˆ†é…å’Œèµ„æºåˆ©ç”¨æ•ˆç‡ä¸é«˜çš„é—®é¢˜</font>**<font style="color:rgb(25, 27, 31);">ã€‚</font>

å¾ˆçƒ‚çš„æœ€æœ€æœ€ä¸€å¼€å§‹çš„é—¨æ§ç½‘ç»œæ˜¯è¿™æ ·çš„ï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759236495391-c8844bb7-0b14-4ae1-a400-edce10f8b132.png)

å¯¹æ‰€æœ‰ä¸“å®¶Eè¾“å…¥äº†xä¹‹åï¼Œå†ç»è¿‡é—¨æ§ç½‘ç»œå»å–å‡ºnä¸ªä¸“å®¶çš„è®¡ç®—ç»“æœï¼Œè¿™æ ·ä¸ºå•¥è¦å¯¹æ‰€æœ‰éƒ½è®¡ç®—å‘¢ï¼Ÿ

ä¸€èˆ¬é—¨æ§ç½‘ç»œæ˜¯è¿™æ ·çš„ï¼š

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759236570140-7e14036d-845d-4b60-bfd4-cd8e16cd9670.png)

å¯¹xä¹˜wgä¹‹ååšsoftmaxï¼Œä¹‹åæŒ‘é€‰æ¦‚ç‡æœ€é«˜çš„ä½œä¸ºé€‰æ‹©çš„ä¸“å®¶

ç¨€ç–æ€§å¼•å…¥äº†ä¸€äº›æœ‰è¶£çš„é€‰æ‹©ï¼Œä¸‡ä¸€æˆ‘ä¸é€‰æ‹©æœ€é«˜çš„ä¸€ä¸ªä¸“å®¶å‘¢ï¼Ÿ

æ¯”å¦‚è¯´è¿™ä¸ªå¼•å…¥äº†å™ªå£°å†é€‰å–å‡ºtopkä¸ªä¸“å®¶çš„ç®—æ³•ï¼š

**å¦‚æœå®Œå…¨ç”¨ç¡®å®šæ€§çš„ Top-K**ï¼Œå®¹æ˜“å‡ºç°ä¸¤ä¸ªé—®é¢˜ï¼š

1. **è´Ÿè½½ä¸å‡è¡¡**ï¼šå°‘æ•°ä¸“å®¶è¢«é¢‘ç¹é€‰æ‹©ï¼Œå…¶ä»–ä¸“å®¶å‡ ä¹æ²¡è¢«ç”¨åˆ°ï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€æµªè´¹å‚æ•°ã€‚
2. **æ¢ç´¢æ€§ä¸è¶³**ï¼šé—¨æ§å±‚å¤ªâ€œè´ªå¿ƒâ€ï¼Œåªç›¯ç€é«˜åˆ†çš„ä¸“å®¶ï¼Œä¸ç»™å…¶ä»–ä¸“å®¶å­¦ä¹ æœºä¼šã€‚

ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼ŒGoogle åœ¨ **Switch Transformer / GShard** é‡Œå¼•å…¥äº† **Noisy Top-K Gating**ã€‚  
åšæ³•æ˜¯ï¼š

åœ¨è®¡ç®—ä¸“å®¶åˆ†æ•°æ—¶ï¼Œ**å¾€æ¯ä¸ªåˆ†æ•°é‡ŒåŠ ä¸€ç‚¹å™ªå£°ï¼ˆé€šå¸¸æ˜¯é«˜æ–¯å™ªå£°ï¼‰**ï¼š

1. s~i=si+Ïµi,Ïµiâˆ¼N(0,Ïƒ2)\tilde{s}_i = s_i + \epsilon_i, \quad \epsilon_i \sim \mathcal{N}(0, \sigma^2)s~i=si+Ïµi,Ïµiâˆ¼N(0,Ïƒ2)

å…¶ä¸­ sis_isi æ˜¯ä¸“å®¶ i çš„åŸå§‹æ‰“åˆ†ï¼ŒÏµi\epsilon_iÏµi æ˜¯å™ªå£°ã€‚

2. ç”¨å¸¦å™ªå£°çš„åˆ†æ•° s~i\tilde{s}_is~i æ¥åš Top-K é€‰æ‹©ã€‚

è¿™æ ·ï¼Œæ¯æ¬¡é€‰æ‹©ä¸“å®¶æ—¶ä¼šæœ‰ä¸€äº›éšæœºæ€§ï¼Œä¸æ˜¯æ€»æŒ‘åˆ†æ•°æœ€é«˜çš„ä¸“å®¶ã€‚

![](https://cdn.nlark.com/yuque/0/2025/png/43288584/1759236762439-62aca437-a18f-4364-8745-b1c4441b5578.png)

åŠ å™ªçš„åŸå› æ˜¯

è¿™æ˜¯æ¯”è¾ƒsoftçš„æ“ä½œï¼Œå…ˆå–å‡ºkä¸ªä¸“å®¶ï¼Œä¹‹åè¿‡äº†è¾¹softmaxï¼Œè·å¾—äº†æ¦‚ç‡åˆ†å¸ƒä¹‹åæ±‚åŠ æƒå’Œæ¥è·å¾—æœ€ç»ˆçš„MoEèåˆç»“æœ

ä¸Šé¢æåˆ°çš„éƒ½æ˜¯shazzeråœ¨LSTMä¸­æåˆ°çš„ã€‚

è´Ÿè½½å‡è¡¡ä¹Ÿå¯ä»¥ä»lossçš„è§’åº¦è§£å†³

è¿˜ä½¿ç”¨äº†è¾…åŠ©æŸå¤±ï¼Œæœ¬è´¨ä¸Šæ˜¯ä¸ªæ­£åˆ™ï¼Œè®©å„ä¸ªä¸“å®¶å¤„ç†å°½å¯èƒ½ä¸€è‡´çš„batchæ•°é‡ã€‚

è¿›ä¸€æ­¥æå‡ï¼š

<font style="color:rgb(25, 27, 31);">è°·æ­Œä½¿ç”¨ </font>[**GShard**](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2006.16668)<font style="color:rgb(25, 27, 31);"> å°è¯•å°† Transformer æ¨¡å‹çš„å‚æ•°é‡æ‰©å±•åˆ°è¶…è¿‡ 6000 äº¿ï¼Œé™¤äº†å¼•å…¥äº†ä¸Šä¸€èŠ‚ä¸­è®¨è®ºçš„ç±»ä¼¼è¾…åŠ©æŸå¤±å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€äº›å…³é”®å˜åŒ–:</font>

<font style="color:rgb(25, 27, 31);">ç»“æ„å±‚é¢ï¼š</font>

<font style="color:rgb(25, 27, 31);">æ¯ä¸ªbatchçš„è·¯ç”±ï¼štopkä¸­çš„top1æ˜¯æ ¹æ®æ’åé€‰å–çš„ï¼Œä½†æ˜¯ç¬¬äºŒä¸ªæ˜¯æ ¹æ®æƒé‡æ¯”ä¾‹éšæœºé€‰æ‹©çš„</font>

**<font style="color:rgb(25, 27, 31);">åˆ†é…batchçš„ä¸Šé™</font>**<font style="color:rgb(25, 27, 31);">: æˆ‘ä»¬å¯ä»¥è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œå®šä¹‰ä¸€ä¸ªä¸“å®¶èƒ½å¤„ç†å¤šå°‘ä»¤ç‰Œã€‚å¦‚æœä¸¤ä¸ªä¸“å®¶çš„å®¹é‡éƒ½è¾¾åˆ°ä¸Šé™ï¼Œä»¤ç‰Œå°±ä¼šæº¢å‡ºï¼Œå¹¶é€šè¿‡æ®‹å·®è¿æ¥ä¼ é€’åˆ°ä¸‹ä¸€å±‚ï¼Œæˆ–åœ¨æŸäº›æƒ…å†µä¸‹è¢«å®Œå…¨ä¸¢å¼ƒã€‚ä¸“å®¶å®¹é‡æ˜¯ MoE ä¸­æœ€é‡è¦çš„æ¦‚å¿µä¹‹ä¸€ã€‚ä¸ºä»€ä¹ˆéœ€è¦ä¸“å®¶å®¹é‡å‘¢ï¼Ÿå› ä¸ºæ‰€æœ‰å¼ é‡çš„å½¢çŠ¶åœ¨ç¼–è¯‘æ—¶æ˜¯é™æ€ç¡®å®šçš„ï¼Œæˆ‘ä»¬æ— æ³•æå‰çŸ¥é“å¤šå°‘ä»¤ç‰Œä¼šåˆ†é…ç»™æ¯ä¸ªä¸“å®¶ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªå›ºå®šçš„å®¹é‡å› å­ã€‚</font>

åé¢23å¹´çš„swin transformerï¼Œå¾®è°ƒMoEçš„æŠ€æœ¯éƒ½å¯ä»¥çœ‹çœ‹

[https://zhuanlan.zhihu.com/p/674698482](https://zhuanlan.zhihu.com/p/674698482) hugging faceç»™å‡ºçš„è¿™ä¸ªæŠ¥å‘Š

å†åˆ°åé¢å°±è‡ªå·±æœä¸€æœ

## Qwen2.5
ä¸€å¥è¯æ€»ç»“ï¼š

<font style="color:rgb(0, 0, 0);background-color:rgb(249, 250, 251);">Qwen2.5 æ˜¯ Qwen å›¢é˜Ÿæ¨å‡ºçš„å…¨é¢å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç³»åˆ—ï¼Œåœ¨</font>**<font style="color:rgb(0, 0, 0) !important;background-color:rgb(249, 250, 251);">é¢„è®­ç»ƒ</font>**<font style="color:rgb(0, 0, 0);background-color:rgb(249, 250, 251);">å’Œ</font>**<font style="color:rgb(0, 0, 0) !important;background-color:rgb(249, 250, 251);">åè®­ç»ƒ</font>**<font style="color:rgb(0, 0, 0);background-color:rgb(249, 250, 251);">é˜¶æ®µå‡æœ‰æ˜¾è‘—æå‡ï¼šé¢„è®­ç»ƒé˜¶æ®µå°†é«˜è´¨é‡æ•°æ®é›†ä» 7 ä¸‡äº¿ token æ‰©å±•è‡³</font>**<font style="color:rgb(0, 0, 0) !important;background-color:rgb(249, 250, 251);">18 ä¸‡äº¿ token</font>**<font style="color:rgb(0, 0, 0);background-color:rgb(249, 250, 251);">ï¼Œä¸ºå¸¸è¯†ã€ä¸“ä¸šçŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›å¥ å®šåŸºç¡€ï¼›åè®­ç»ƒé˜¶æ®µé€šè¿‡è¶… 100 ä¸‡æ ·æœ¬çš„ç²¾ç»†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åŠå¤šé˜¶æ®µå¼ºåŒ–å­¦ä¹ ï¼ˆå«ç¦»çº¿ DPO å’Œåœ¨çº¿ GRPOï¼‰ï¼Œå¤§å¹…ä¼˜åŒ–äººç±»åå¥½å¯¹é½ã€é•¿æ–‡æœ¬ç”Ÿæˆç­‰èƒ½åŠ›ã€‚è¯¥ç³»åˆ—æä¾›ä¸°å¯Œé…ç½®ï¼Œå¼€æºæ¨¡å‹æ¶µç›–</font>**<font style="color:rgb(0, 0, 0) !important;background-color:rgb(249, 250, 251);">0.5B è‡³ 72B å‚æ•°</font>**<font style="color:rgb(0, 0, 0);background-color:rgb(249, 250, 251);">çš„åŸºç¡€æ¨¡å‹ä¸æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ï¼ˆå«é‡åŒ–ç‰ˆæœ¬ï¼‰ï¼Œä¸“æœ‰æ¨¡å‹å« Qwen2.5Turbo å’Œ Qwen2.5-Plus ä¸¤æ¬¾ MoE å˜ä½“ï¼›åœ¨åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°é¡¶å°–ï¼Œå¦‚å¼€æºæ——èˆ°æ¨¡å‹ Qwen2.5-72B-Instruct æ€§èƒ½åª²ç¾å‚æ•°çº¦ä¸ºå…¶ 5 å€çš„ Llama-3-405B-Instructï¼Œä¸”å¯ä½œä¸ºåŸºç¡€æ¨¡å‹æ”¯æ’‘ Qwen2.5-Math ç­‰ä¸“ä¸šæ¨¡å‹çš„è®­ç»ƒï¼Œé€‚ç”¨äºå­¦æœ¯ä¸å·¥ä¸šåœºæ™¯ã€‚</font>

<details class="lake-collapse"><summary id="u39ba1423"><span class="ne-text" style="font-size: 16px">è§£é‡Šï¼šæ•°æ®é›†å¤§å°</span></summary><p id="u5ad43971" class="ne-p"><br></p><h2 id="mxJdt"><span class="ne-text"><br /></span><span class="ne-text"> </span></h2></details>
<details class="lake-collapse"><summary id="u9b24341a"><span class="ne-text" style="font-size: 16px">è§£é‡Šï¼šå¼ºåŒ–å­¦ä¹ çš„åœ¨çº¿ç¦»çº¿</span></summary><h3 id="KDztG"><span class="ne-text">1. ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOffline RLï¼‰</span></h3><ul class="ne-ul"><li id="uc7d5cda9" data-lake-index-type="0"><strong><span class="ne-text">æ•°æ®æ¥æº</span></strong><span class="ne-text">ï¼šå®Œå…¨ä¾èµ– </span><strong><span class="ne-text">å·²æœ‰çš„äººç±»åé¦ˆæ•°æ®é›†</span></strong><span class="ne-text">ï¼ˆæ¯”å¦‚ï¼Œäººç±»å¯¹æ¨¡å‹å›ç­”çš„æ’åº/åå¥½ã€æ ‡æ³¨å¥½çš„è¯„åˆ†ï¼‰ã€‚</span></li><li id="u9cf6b046" data-lake-index-type="0"><strong><span class="ne-text">è®­ç»ƒæ–¹å¼</span></strong><span class="ne-text">ï¼šæ¨¡å‹ä¸ä¼šå’Œç¯å¢ƒå®æ—¶äº¤äº’ï¼Œè€Œæ˜¯ä»è¿™äº›é™æ€æ•°æ®ä¸­å­¦ä¹ ã€‚</span></li><li id="u76051bf1" data-lake-index-type="0"><strong><span class="ne-text">ä¼˜åŠ¿</span></strong><span class="ne-text">ï¼š</span></li></ul><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="ua937afd5" data-lake-index-type="0"><span class="ne-text">ä¸éœ€è¦å®æ—¶é‡‡æ ·ï¼Œæˆæœ¬ä½ã€‚</span></li><li id="ue39daa63" data-lake-index-type="0"><span class="ne-text">æ•°æ®å¯æ§ï¼Œæ ‡æ³¨è´¨é‡é«˜ã€‚</span></li></ul></ul><ul class="ne-ul"><li id="uda7af251" data-lake-index-type="0"><strong><span class="ne-text">å…¸å‹åº”ç”¨</span></strong><span class="ne-text">ï¼šåƒ </span><strong><span class="ne-text">DPOï¼ˆDirect Preference Optimizationï¼‰</span></strong><span class="ne-text"> å°±æ˜¯å…¸å‹çš„ç¦»çº¿ RL ç®—æ³•ï¼Œå®ƒç›´æ¥åˆ©ç”¨ç¦»çº¿åå¥½æ•°æ®è¿›è¡Œä¼˜åŒ–ï¼Œè®©æ¨¡å‹å›ç­”æ›´ç¬¦åˆäººç±»åå¥½ã€‚</span></li></ul><p id="ucd49a519" class="ne-p"><span class="ne-text">ğŸ‘‰</span><span class="ne-text"> ç±»æ¯”ï¼šå°±åƒå­¦ç”Ÿé€šè¿‡çœ‹å¾€å¹´çš„æ ‡å‡†ç­”æ¡ˆå’Œè¯„åˆ†è§„åˆ™ï¼Œè‡ªå­¦æ€ä¹ˆç­”é¢˜æ›´å—è€å¸ˆå–œæ¬¢ã€‚</span></p><hr id="dh7Yo" class="ne-hr"><h3 id="d260b6c1"><span class="ne-text">2. åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOnline RLï¼‰</span></h3><ul class="ne-ul"><li id="uaaa47875" data-lake-index-type="0"><strong><span class="ne-text">æ•°æ®æ¥æº</span></strong><span class="ne-text">ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ—¶ä¼š </span><strong><span class="ne-text">å®æ—¶ç”Ÿæˆå›ç­”</span></strong><span class="ne-text">ï¼Œç„¶åé€šè¿‡äººç±»åé¦ˆæˆ–è‡ªåŠ¨å¥–åŠ±æ¨¡å‹æ¥æ‰“åˆ†ï¼Œå†æ®æ­¤æ›´æ–°ç­–ç•¥ã€‚</span></li><li id="ue23a716d" data-lake-index-type="0"><strong><span class="ne-text">è®­ç»ƒæ–¹å¼</span></strong><span class="ne-text">ï¼šæ¨¡å‹è¾¹ç”Ÿæˆã€è¾¹è¢«è¯„ä¼°ã€è¾¹æ›´æ–°ï¼Œå½¢æˆâ€œäº¤äº’â€”åé¦ˆâ€”ä¼˜åŒ–â€çš„å¾ªç¯ã€‚</span></li><li id="ubce80608" data-lake-index-type="0"><strong><span class="ne-text">ä¼˜åŠ¿</span></strong><span class="ne-text">ï¼š</span></li></ul><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u15d1947e" data-lake-index-type="0"><span class="ne-text">èƒ½å¤Ÿæ¢ç´¢æ›´ä¸°å¯Œçš„å›ç­”ç©ºé—´ã€‚</span></li><li id="u7475c7e4" data-lake-index-type="0"><span class="ne-text">å¥–åŠ±å‡½æ•°å¯åŠ¨æ€è°ƒæ•´ï¼Œæ›´è´´è¿‘çœŸå®äººç±»åå¥½ã€‚</span></li></ul></ul><ul class="ne-ul"><li id="u8ceed448" data-lake-index-type="0"><strong><span class="ne-text">å…¸å‹åº”ç”¨</span></strong><span class="ne-text">ï¼šQwen2.5 é‡Œçš„ </span><strong><span class="ne-text">GRPOï¼ˆGroup Relative Policy Optimizationï¼‰</span></strong><span class="ne-text"> å°±æ˜¯åœ¨çº¿ RL çš„ä¸€ä¸ªå˜ä½“ï¼Œé€šè¿‡ä¸æ–­é‡‡æ ·å’Œæ¯”è¾ƒä¸åŒå›ç­”ï¼Œå®æ—¶ä¼˜åŒ–æ¨¡å‹è¡Œä¸ºã€‚</span></li></ul><p id="u52f0cdd7" class="ne-p"><span class="ne-text">ğŸ‘‰</span><span class="ne-text"> ç±»æ¯”ï¼šå°±åƒå­¦ç”Ÿç­”é¢˜åï¼Œè€å¸ˆç«‹å³ç»™åé¦ˆï¼ˆæ¯”å¦‚æ‰“åˆ†æˆ–ç‚¹è¯„ï¼‰ï¼Œå­¦ç”Ÿæ®æ­¤æ”¹è¿›ç­”é¢˜ç­–ç•¥ã€‚</span></p><p id="ue2ed8f12" class="ne-p"><span class="ne-text"></span></p></details>
### denseæ¨¡å‹æ¶æ„
#### GQA group query attention
å‚è€ƒï¼š

[https://zhuanlan.zhihu.com/p/686149289](https://zhuanlan.zhihu.com/p/686149289)

äº†è§£è¿™ä¸ªä¹‹å‰å…ˆäº†è§£ä¸‹KV cache

[https://zhuanlan.zhihu.com/p/662498827](https://zhuanlan.zhihu.com/p/662498827)

è¿™ç¯‡è¯´çš„è›®å¥½çš„ï¼Œåœ¨æ¯æ¬¡è¿›è¡Œattention scoreè®¡ç®—çš„æ—¶å€™ï¼Œç”±äºmaskçš„æ•ˆåº”ï¼Œ**<font style="color:rgb(25, 27, 31);">æ¨ç†ç¬¬ xkä¸ªå­—ç¬¦çš„æ—¶å€™åªéœ€è¦è¾“å…¥xk-1çš„å­—ç¬¦å³å¯ã€‚</font>**

<font style="color:rgb(25, 27, 31);">å› æ­¤æ¯æ¬¡åªè¦æŠŠxk-1çš„Kå’ŒVå…¨éƒ¨å­˜åˆ°cacheå½“ä¸­ï¼Œåœ¨éœ€è¦çš„æ—¶å€™å–å‡ºæ¥ç”¨ï¼Œè¿™æ ·æ¯æ¬¡åªéœ€è¦è®¡ç®—ç¬¬kä¸ªKå’ŒVå³å¯çš„å³å¯</font>

<font style="color:rgb(25, 27, 31);">è®¡ç®—çš„æ–¹å¼ä¹Ÿå°±æ˜¯kvçŸ©é˜µçš„å¤§å°b*s*h*d*d_typeå†ä¹˜ä¸Šæ¨¡å‹çš„å±‚æ•°då†ä¹˜*2ï¼Œè¿™ä¸ªæ•°å­—é‡å¾ˆå®¹æ˜“ä¸Š1Gï¼Œè¿™æ—¶å€™å°±éœ€è¦MQAå’ŒGQAä¸Šåœºäº†</font>

<font style="color:rgb(25, 27, 31);">MQAæ˜¯åªç”¨ä¸€ä¸ªkå’Œvï¼Œå½“æ—¶å†ç»è¿‡wqï¼Œwkï¼Œwvçš„æ—¶å€™æŠŠçŸ©é˜µæŠ•å½±æˆäº†ï¼ˆb,s,head,head_dim)</font>

<font style="color:rgb(25, 27, 31);">ç°åœ¨å› ä¸ºk,vå æ¯”å¤ªå¤§äº†ï¼Œå°±æŠŠæŠ•å½±æˆäº†(b,s,head_dim)ï¼Œä¹‹åé€šè¿‡repeaté‡å¤å¹¶æ‰©å……æˆheadä¸ªæ•°ï¼Œå¹¶åšattention map</font>

<font style="color:rgb(25, 27, 31);">è€ŒGQAå°±æ˜¯ä¸“é—¨è®¾è®¡äº†ä¸ªargs.kv_headï¼Œä¹‹åç»è¿‡wk,wvæŠ•å½±æˆè¿™ä¸ªå¤§å°ã€‚åœ¨scoreä¹‹å‰ï¼Œropeä¹‹åé‡å¤ï¼Œå¹¶åšattention map</font>

#### Dual chunk attention
è¿™é‡Œä¸»è¦å‚è€ƒChatGPT

ç”¨æ¥å‡å°‘å¤æ‚åº¦ï¼ŒåŸæ¥è®¡ç®—å¤æ‚åº¦æ˜¯n^2d

ç°åœ¨DCAå§attentionæ‹†åˆ†æˆäº†å¤šä¸ªchunkï¼Œchunkå†…è®¡ç®—attnentionï¼Œchunké—´æ˜¯å¯¹chunkå†…çš„tokenè¿›è¡ŒæŠ½å–ï¼Œå¹¶è®¡ç®—chunkä¹‹é—´çš„scoreã€‚ç»¼åˆè®¡ç®—å¤æ‚åº¦å¦‚ä¸‹è®¡ç®—ï¼š

<details class="lake-collapse"><summary id="u8ba9e9b5"><span class="ne-text">DCA scoreè®¡ç®—å¤æ‚åº¦</span></summary><h3 id="NViEB"><span class="ne-text">å±€éƒ¨å—å†… attention çš„é€»è¾‘</span></h3><p id="ue41c46d9" class="ne-p"><span class="ne-text">åœ¨ </span><strong><span class="ne-text">dual chunk attention</span></strong><span class="ne-text"> é‡Œï¼Œæˆ‘ä»¬æŠŠåºåˆ—åˆ‡æˆè‹¥å¹²ä¸ª </span><strong><span class="ne-text">chunk</span></strong><span class="ne-text">ï¼Œæ¯ä¸ª chunk å¤§å°æ˜¯ </span><span class="ne-text">c</span><span class="ne-text">c</span><span class="ne-text">c</span><span class="ne-text">ã€‚</span></p><ul class="ne-ul"><li id="u4163adfb" data-lake-index-type="0"><span class="ne-text">å‡è®¾æ€»é•¿åº¦æ˜¯ </span><span class="ne-text">n</span><span class="ne-text">n</span><span class="ne-text">n</span><span class="ne-text">ï¼Œé‚£ä¹ˆæ€»å…±æœ‰ </span><span class="ne-text">n</span><span class="ne-text">/</span><span class="ne-text">c</span><span class="ne-text">n/c</span><span class="ne-text">n</span><span class="ne-text">/</span><span class="ne-text">c</span><span class="ne-text"> ä¸ª chunkã€‚</span></li><li id="u0220ad69" data-lake-index-type="0"><strong><span class="ne-text">å±€éƒ¨å—å†… attention</span></strong><span class="ne-text">ï¼š<br /></span><span class="ne-text">æ¯ä¸ª token </span><strong><span class="ne-text">åªå’Œè‡ªå·±æ‰€åœ¨çš„ chunk å†…çš„ token äº¤äº’</span></strong><span class="ne-text">ï¼Œè€Œä¸æ˜¯å’Œæ•´ä¸ªåºåˆ—ã€‚</span></li></ul><hr id="ZQk8b" class="ne-hr"><h3 id="YXn5V"><span class="ne-text">å¤æ‚åº¦æ¨å¯¼</span></h3><ol class="ne-ol"><li id="u590e409c" data-lake-index-type="0"><strong><span class="ne-text">ä¸€ä¸ª token çš„è®¡ç®—é‡</span></strong></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u669eef9d" data-lake-index-type="0"><span class="ne-text">æ¯ä¸ª token éœ€è¦å’ŒåŒ chunk çš„ </span><span class="ne-text">c</span><span class="ne-text">c</span><span class="ne-text">c</span><span class="ne-text"> ä¸ª token åš dot-productï¼ˆQK ä¹˜æ³•ï¼‰ï¼Œ</span></li><li id="u85b04ead" data-lake-index-type="0"><span class="ne-text">æ¯æ¬¡ dot-product æ˜¯ </span><span class="ne-text">O</span><span class="ne-text">(</span><span class="ne-text">d</span><span class="ne-text">)</span><span class="ne-text">O(d)</span><span class="ne-text">O</span><span class="ne-text">(</span><span class="ne-text">d</span><span class="ne-text">)</span><span class="ne-text"> çš„è¿ç®—ï¼ˆå› ä¸ºå‘é‡ç»´åº¦æ˜¯ </span><span class="ne-text">d</span><span class="ne-text">d</span><span class="ne-text">d</span><span class="ne-text">ï¼‰ã€‚</span></li><li id="ucc741d8f" data-lake-index-type="0"><span class="ne-text">æ‰€ä»¥ä¸€ä¸ª token çš„å¤æ‚åº¦ = </span><span class="ne-text">O</span><span class="ne-text">(</span><span class="ne-text">c</span><span class="ne-text">â‹…</span><span class="ne-text">d</span><span class="ne-text">)</span><span class="ne-text">O(c \cdot d)</span><span class="ne-text">O</span><span class="ne-text">(</span><span class="ne-text">c</span><span class="ne-text">â‹…</span><span class="ne-text">d</span><span class="ne-text">)</span><span class="ne-text">ã€‚</span></li></ul></ul><ol start="2" class="ne-ol"><li id="u1dad9ecb" data-lake-index-type="0"><strong><span class="ne-text">n ä¸ª token çš„è®¡ç®—é‡</span></strong></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="ue9c11c90" data-lake-index-type="0"><span class="ne-text">ä¸€å…±æœ‰ </span><span class="ne-text">n</span><span class="ne-text">n</span><span class="ne-text">n</span><span class="ne-text"> ä¸ª tokenï¼Œ</span></li><li id="u5b883b83" data-lake-index-type="0"><span class="ne-text">æ‰€ä»¥æ€»å¤æ‚åº¦ = O(nâ‹…câ‹…d)O(n \cdot c \cdot d)O(nâ‹…câ‹…d)ã€‚</span></li></ul></ul><p id="ud9f41677" class="ne-p"><span class="ne-text"></span></p><h3 id="6e3b8327"><span class="ne-text">(2) è·¨å—ï¼ˆglobal / summaryï¼‰attention</span></h3><p id="u69fb6f72" class="ne-p"><span class="ne-text">è¿™é‡Œæœ‰å¤šç§å®ç°æ–¹å¼ï¼Œä½†ä¸€èˆ¬ä¸åšç¨ å¯†çš„å…¨å±€ attentionï¼Œè€Œæ˜¯</span><strong><span class="ne-text">å—çº§ç¨€ç–</span></strong><span class="ne-text">ï¼š</span></p><ul class="ne-ul"><li id="u09cf9d4b" data-lake-index-type="0"><span class="ne-text">å¦‚æœæ¯ä¸ª chunk æå– 1 ä¸ª summary tokenï¼ˆæˆ–å°‘é‡ </span><span class="ne-text">s</span><span class="ne-text">s</span><span class="ne-text">s</span><span class="ne-text"> ä¸ª tokenï¼‰ï¼Œ<br /></span><span class="ne-text">é‚£ä¹ˆæ€» summary token æ•°é‡ </span><span class="ne-text">â‰ˆ</span><span class="ne-text">m</span><span class="ne-text">\approx m</span><span class="ne-text">â‰ˆ</span><span class="ne-text">m</span><span class="ne-text">ã€‚</span></li><li id="u86e82b20" data-lake-index-type="0"><span class="ne-text">summary token ä¹‹é—´å…¨è¿æ¥ï¼š</span></li></ul><p id="u2f5c9cf0" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2025/png/43288584/1759232324680-ff76887a-7c6f-4128-bec5-19d76136bdb6.png" width="262.6666666666667" id="u754de320" class="ne-image"></p><ul class="ne-ul"><li id="u882ad564" data-lake-index-type="0"><span class="ne-text">æˆ–è€…æ¯ä¸ª token attends åˆ° summary tokenï¼š</span></li></ul><p id="u07097785" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2025/png/43288584/1759232331703-20341d5f-5f98-4a0f-b201-fd7d2a41bcc2.png" width="268" id="uc639dde3" class="ne-image"></p></details>


<font style="color:rgb(25, 27, 31);"> </font>



<font style="color:rgb(25, 27, 31);"></font>

<font style="color:rgb(25, 27, 31);"></font>

## 
